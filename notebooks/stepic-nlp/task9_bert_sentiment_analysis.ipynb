{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cpu':\n",
    "    print('cpu')\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ROOT_PATH = \"../../data/raw/mokoron_tweeter_sentiments/\"\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "pos_texts = pd.read_csv(f'{ROOT_PATH}positive.csv', encoding='utf8', sep=';', header=None)\n",
    "neg_texts = pd.read_csv(f'{ROOT_PATH}negative.csv', encoding='utf8', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14088</th>\n",
       "      <td>409333469203152896</td>\n",
       "      <td>1386427678</td>\n",
       "      <td>OlyaKulak</td>\n",
       "      <td>RT @Alina_Strukova: весело сегодня было на вок...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59837</th>\n",
       "      <td>410142690177978368</td>\n",
       "      <td>1386620612</td>\n",
       "      <td>olga_avramova</td>\n",
       "      <td>Всё время видемся,но никогда норм не поговорим...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3377</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98679</th>\n",
       "      <td>411056122385403904</td>\n",
       "      <td>1386838391</td>\n",
       "      <td>MadinkaGaripova</td>\n",
       "      <td>Даже и не думаешь,как все хорошо:)\\nСпасибо те...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84056</th>\n",
       "      <td>410781100512772096</td>\n",
       "      <td>1386772820</td>\n",
       "      <td>negDmeD</td>\n",
       "      <td>@Maralbugaa @Uria_b хааааа 21 хурээд 2 сар бол...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6432</td>\n",
       "      <td>1214</td>\n",
       "      <td>2075</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104113</th>\n",
       "      <td>411118129050185728</td>\n",
       "      <td>1386853174</td>\n",
       "      <td>Stephen_true</td>\n",
       "      <td>Аарон, я буду ждать того дня, когда ты переста...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6694</td>\n",
       "      <td>82</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0           1                2   \\\n",
       "14088   409333469203152896  1386427678        OlyaKulak   \n",
       "59837   410142690177978368  1386620612    olga_avramova   \n",
       "98679   411056122385403904  1386838391  MadinkaGaripova   \n",
       "84056   410781100512772096  1386772820          negDmeD   \n",
       "104113  411118129050185728  1386853174     Stephen_true   \n",
       "\n",
       "                                                       3   4   5   6   7   \\\n",
       "14088   RT @Alina_Strukova: весело сегодня было на вок...   1   0   1   0   \n",
       "59837   Всё время видемся,но никогда норм не поговорим...   1   0   0   0   \n",
       "98679   Даже и не думаешь,как все хорошо:)\\nСпасибо те...   1   0   0   0   \n",
       "84056   @Maralbugaa @Uria_b хааааа 21 хурээд 2 сар бол...   1   0   0   0   \n",
       "104113  Аарон, я буду ждать того дня, когда ты переста...   1   0   0   0   \n",
       "\n",
       "          8     9     10  11  \n",
       "14088    968    20    22   0  \n",
       "59837   3377    57    53   0  \n",
       "98679     32    52    52   0  \n",
       "84056   6432  1214  2075   4  \n",
       "104113  6694    82    68   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_texts.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n",
    "\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Люблю маму и папу!!!!а в остальное я так...-влюбляюсь, привязываюсь)))  [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158783 68051\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gt), len(test_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'д', '##а', '##ж', '##е', '5', 'п', '##о', 'а', '##н', '##г', '##л', '##ии', '##с', '##к', '##о', '##м', '##у', 'в', 'э', '##т', '##о', '##и', 'ч', '##е', '##т', '##в', '##е', '##р', '##т', '##и', 'н', '##е', 'в', '##ы', '##х', '##о', '##д', '##и', '##т', ',', 'н', '##у', 'к', '##а', '##к', 'т', '##а', '##к', '-', 'т', '##о', '?', ':', '(', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Даже 5 по английскому в этой четверти не выходит, ну как так-то? :( [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    input_ids, train_gt, \n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    attention_masks,\n",
    "    input_ids,\n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    sampler=SequentialSampler(validation_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109483778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss на обучающей выборке: 0.03626\n",
      "CPU times: user 46min 39s, sys: 17.4 s, total: 46min 56s\n",
      "Wall time: 46min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "# Обучение\n",
    "# Переводим модель в training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss[0].backward()\n",
    "    \n",
    "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем loss\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "    # Рисуем график\n",
    "    clear_output(True)\n",
    "    plt.plot(train_loss_set)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидация\n",
    "# Переводим модель в evaluation mode\n",
    "model.eval()\n",
    "\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in validation_dataloader:   \n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)     \n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на валидационной выборке: 98.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-564f4a8b4f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m print('Неправильных предсказаний: {0}/{1}'.format(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "print('Неправильных предсказаний: {0}/{1}'.format(\n",
    "    sum(test_labels != test_preds),\n",
    "    len(test_labels)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(test_gt)\n",
    "\n",
    "prediction_data = TensorDataset(\n",
    "    prediction_inputs,\n",
    "    prediction_masks,\n",
    "    prediction_labels\n",
    ")\n",
    "\n",
    "prediction_dataloader = DataLoader(\n",
    "    prediction_data, \n",
    "    sampler=SequentialSampler(prediction_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Сохраняем предсказанные классы и ground truth\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)  \n",
    "    test_preds.extend(batch_preds)\n",
    "    test_labels.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на отложенной выборке составил: 97.99%\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(test_labels, test_preds)\n",
    "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
    "    acc_score*100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-564f4a8b4f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m print('Неправильных предсказаний: {0}/{1}'.format(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "print('Неправильных предсказаний: {0}/{1}'.format(\n",
    "    sum(test_labels != test_preds),\n",
    "    len(test_labels)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
