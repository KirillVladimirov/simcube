{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby, accumulate\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_toolbelt import losses as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ss = pd.read_csv(\"../../data/raw/liverpool-ion-switching/sample_submission.csv\", dtype={'time':str})\n",
    "train = pd.read_csv('../../data/raw/liverpool-ion-switching/train.csv')\n",
    "train['filter'] = 0\n",
    "test = pd.read_csv('../../data/raw/liverpool-ion-switching/test.csv')\n",
    "test['filter'] = 2\n",
    "ts1 = pd.concat([train, test], axis=0, sort=False).reset_index(drop=True)\n",
    "\n",
    "ts1['time2'] = pd.cut(ts1['time'], bins=np.linspace(0.0000, 700., num=14 + 1), labels=list(range(14)), include_lowest=True).astype(int)\n",
    "ts1['time2'] = ts1.groupby('time2')['time'].rank( )/500000.\n",
    "\n",
    "np.random.seed(321)\n",
    "ts1['group'] = pd.cut(ts1['time'], bins=np.linspace(0.0000, 700., num=14*125 + 1), labels=list(range(14*125)), include_lowest=True).astype(int)\n",
    "np.random.seed(321)\n",
    "\n",
    "y = ts1.loc[ts1['filter']==0, 'open_channels']\n",
    "group = ts1.loc[ts1['filter']==0, 'group']\n",
    "X = ts1.loc[ts1['filter']==0, 'signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)\n",
    "skf = GroupKFold(n_splits=5)\n",
    "splits = [x for x in skf.split(X, y, group)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [col for col in ts1.columns if col not in ['index','filter','group', 'open_channels', 'time', 'time2']]  \n",
    "\n",
    "# Create numpy array of inputs\n",
    "for col in use_cols:\n",
    "    col_mean = ts1[col].mean()\n",
    "    ts1[col] = ts1[col].fillna(col_mean)\n",
    "\n",
    "    \n",
    "val_preds_all = np.zeros((ts1[ts1['filter']==0].shape[0], 11))\n",
    "test_preds_all = np.zeros((ts1[ts1['filter']==2].shape[0], 11))\n",
    "\n",
    "groups = ts1.loc[ts1['filter']==0, 'group']\n",
    "times = ts1.loc[ts1['filter']==0, 'time']\n",
    "\n",
    "new_splits = []\n",
    "for sp in splits:\n",
    "    new_split = []\n",
    "    new_split.append(np.unique(groups[sp[0]]))\n",
    "    new_split.append(np.unique(groups[sp[1]]))\n",
    "    new_splits.append(new_split)\n",
    "    \n",
    "trainval = np.array(list(ts1[ts1['filter']==0].groupby('group').apply(lambda x: x[use_cols].values)))\n",
    "test = np.array(list(ts1[ts1['filter']==2].groupby('group').apply(lambda x: x[use_cols].values)))\n",
    "trainval_y = np.array(list(ts1[ts1['filter']==0].groupby('group').apply(lambda x: x[['open_channels']].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# transpose to B x C x L\n",
    "trainval = trainval.transpose((0,2,1))\n",
    "test = test.transpose((0,2,1))\n",
    "\n",
    "trainval_y = trainval_y.reshape(trainval_y.shape[:2])\n",
    "test_y = np.zeros((test.shape[0], trainval_y.shape[1]))\n",
    "\n",
    "trainval = torch.Tensor(trainval)\n",
    "test = torch.Tensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, checkpoint_path='checkpoint.pt', is_maximize=True):\n",
    "        self.patience, self.delta, self.checkpoint_path = patience, delta, checkpoint_path\n",
    "        self.counter, self.best_score = 0, None\n",
    "        self.is_maximize = is_maximize\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        model.load_state_dict(torch.load(self.checkpoint_path))\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None or \\\n",
    "        (score > self.best_score + self.delta if self.is_maximize else score < self.best_score - self.delta):\n",
    "            torch.save(model.state_dict(), self.checkpoint_path)\n",
    "            self.best_score, self.counter = score, 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRnn(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, output_size, num_layers=1, bidirectional=False, dropout=.3,\n",
    "            hidden_layers = [100, 200]):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.bidirectional=bidirectional\n",
    "        self.output_size=output_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           bidirectional=bidirectional, batch_first=True, dropout=0.3)\n",
    "         # Input Layer\n",
    "        if hidden_layers and len(hidden_layers):\n",
    "            first_layer  = nn.Linear(hidden_size*2 if bidirectional else hidden_size, hidden_layers[0])\n",
    "\n",
    "            # Hidden Layers\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [first_layer]+[nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers) - 1)]\n",
    "            )\n",
    "            for layer in self.hidden_layers: nn.init.kaiming_normal_(layer.weight.data)   \n",
    "\n",
    "            self.intermediate_layer = nn.Linear(hidden_layers[-1], self.input_size)\n",
    "            # output layers\n",
    "            self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "           \n",
    "        else:\n",
    "            self.hidden_layers = []\n",
    "            self.intermediate_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_siz, self.input_size)\n",
    "            self.output_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_size, output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "\n",
    "        self.activation_fn = torch.relu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        outputs, hidden = self.rnn(x)        \n",
    "\n",
    "        x = self.dropout(self.activation_fn(outputs))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fn(hidden_layer(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IonDataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data, labels, training=True, transform=None, flip=0.5, noise_level=0, class_split=0.0):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "        self.flip = flip\n",
    "        self.noise_level = noise_level\n",
    "        self.class_split = class_split\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "        if np.random.rand() < self.class_split:\n",
    "            data, labels = class_split(data, labels)\n",
    "        if  np.random.rand() < self.noise_level:\n",
    "            data = data * torch.FloatTensor(10000).uniform_(1-self.noise_level, 1+self.noise_level)\n",
    "        if np.random.rand() < self.flip:\n",
    "            data = torch.flip(data, dims=[1])\n",
    "            labels = np.flip(labels, axis=0).copy().astype(int)\n",
    "\n",
    "        return [data, labels.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "Epoch : 0\n",
      "learning_rate: 0.000001000\n",
      "train_loss: 2.429077, valid_loss: 2.111174\n",
      "train_f1: 0.063725, valid_f1: 0.012603\n",
      "--- 35.07161021232605 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000011938\n",
      "train_loss: 2.222745, valid_loss: 1.911275\n",
      "train_f1: 0.067881, valid_f1: 0.012206\n",
      "--- 35.41838526725769 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000044274\n",
      "train_loss: 1.915994, valid_loss: 1.619343\n",
      "train_f1: 0.079272, valid_f1: 0.092356\n",
      "--- 35.21872854232788 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000096592\n",
      "train_loss: 1.539222, valid_loss: 0.980664\n",
      "train_f1: 0.105903, valid_f1: 0.103237\n",
      "--- 35.66316771507263 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000166599\n",
      "train_loss: 1.119199, valid_loss: 0.737225\n",
      "train_f1: 0.135018, valid_f1: 0.105530\n",
      "--- 35.59089231491089 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000251230\n",
      "train_loss: 0.904176, valid_loss: 0.659266\n",
      "train_f1: 0.152963, valid_f1: 0.133027\n",
      "--- 35.21375036239624 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000346779\n",
      "train_loss: 0.787489, valid_loss: 0.631828\n",
      "train_f1: 0.172646, valid_f1: 0.152598\n",
      "--- 35.06817054748535 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000449060\n",
      "train_loss: 0.720459, valid_loss: 0.607402\n",
      "train_f1: 0.184116, valid_f1: 0.150187\n",
      "--- 35.78777551651001 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000553594\n",
      "train_loss: 0.677602, valid_loss: 0.597480\n",
      "train_f1: 0.193116, valid_f1: 0.164331\n",
      "--- 35.84958791732788 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000655802\n",
      "train_loss: 0.648910, valid_loss: 0.576580\n",
      "train_f1: 0.202434, valid_f1: 0.173125\n",
      "--- 35.691149950027466 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000751209\n",
      "train_loss: 0.621385, valid_loss: 0.543580\n",
      "train_f1: 0.218357, valid_f1: 0.226044\n",
      "--- 35.931567430496216 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000835636\n",
      "train_loss: 0.588201, valid_loss: 0.515656\n",
      "train_f1: 0.251963, valid_f1: 0.250771\n",
      "--- 35.896657943725586 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000905384\n",
      "train_loss: 0.554895, valid_loss: 0.468228\n",
      "train_f1: 0.283302, valid_f1: 0.319117\n",
      "--- 35.54656505584717 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000957400\n",
      "train_loss: 0.533242, valid_loss: 0.458651\n",
      "train_f1: 0.303341, valid_f1: 0.351143\n",
      "--- 35.661396503448486 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000989405\n",
      "train_loss: 0.502900, valid_loss: 0.420597\n",
      "train_f1: 0.327806, valid_f1: 0.350609\n",
      "--- 35.13721752166748 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.001000000\n",
      "train_loss: 0.475059, valid_loss: 0.390077\n",
      "train_f1: 0.352416, valid_f1: 0.389813\n",
      "--- 35.70624232292175 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999860\n",
      "train_loss: 0.449655, valid_loss: 0.376003\n",
      "train_f1: 0.381110, valid_f1: 0.380734\n",
      "--- 35.59257674217224 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999450\n",
      "train_loss: 0.422650, valid_loss: 0.340335\n",
      "train_f1: 0.406397, valid_f1: 0.448563\n",
      "--- 35.14987850189209 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998769\n",
      "train_loss: 0.418034, valid_loss: 0.349319\n",
      "train_f1: 0.429661, valid_f1: 0.479783\n",
      "--- 35.334176540374756 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997818\n",
      "train_loss: 0.391046, valid_loss: 0.305238\n",
      "train_f1: 0.454261, valid_f1: 0.569614\n",
      "--- 35.620049476623535 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996598\n",
      "train_loss: 0.360704, valid_loss: 0.273957\n",
      "train_f1: 0.487436, valid_f1: 0.611641\n",
      "--- 36.759955167770386 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000995108\n",
      "train_loss: 0.345320, valid_loss: 0.287766\n",
      "train_f1: 0.506507, valid_f1: 0.578234\n",
      "--- 36.34266257286072 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993351\n",
      "train_loss: 0.328824, valid_loss: 0.243858\n",
      "train_f1: 0.529366, valid_f1: 0.646147\n",
      "--- 34.72471737861633 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991326\n",
      "train_loss: 0.308561, valid_loss: 0.227162\n",
      "train_f1: 0.551566, valid_f1: 0.666719\n",
      "--- 35.46201038360596 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000989035\n",
      "train_loss: 0.299844, valid_loss: 0.221668\n",
      "train_f1: 0.565429, valid_f1: 0.665203\n",
      "--- 35.87040829658508 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986480\n",
      "train_loss: 0.288692, valid_loss: 0.238689\n",
      "train_f1: 0.582886, valid_f1: 0.676490\n",
      "--- 36.04136800765991 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983661\n",
      "train_loss: 0.280974, valid_loss: 0.213896\n",
      "train_f1: 0.597565, valid_f1: 0.685511\n",
      "--- 35.585087299346924 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980580\n",
      "train_loss: 0.268292, valid_loss: 0.197115\n",
      "train_f1: 0.613865, valid_f1: 0.724951\n",
      "--- 35.7377769947052 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000977239\n",
      "train_loss: 0.256066, valid_loss: 0.184313\n",
      "train_f1: 0.634010, valid_f1: 0.745787\n",
      "--- 35.1488938331604 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973639\n",
      "train_loss: 0.250201, valid_loss: 0.174752\n",
      "train_f1: 0.642125, valid_f1: 0.752435\n",
      "--- 35.93227767944336 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969783\n",
      "train_loss: 0.238607, valid_loss: 0.166557\n",
      "train_f1: 0.658682, valid_f1: 0.751265\n",
      "--- 35.430258989334106 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965673\n",
      "train_loss: 0.257788, valid_loss: 0.167391\n",
      "train_f1: 0.640719, valid_f1: 0.761156\n",
      "--- 35.236735820770264 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000961310\n",
      "train_loss: 0.224920, valid_loss: 0.157000\n",
      "train_f1: 0.676832, valid_f1: 0.760268\n",
      "--- 35.61929249763489 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956698\n",
      "train_loss: 0.218065, valid_loss: 0.149744\n",
      "train_f1: 0.686771, valid_f1: 0.771275\n",
      "--- 35.723976612091064 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951838\n",
      "train_loss: 0.209254, valid_loss: 0.144173\n",
      "train_f1: 0.696907, valid_f1: 0.773870\n",
      "--- 35.18752408027649 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946733\n",
      "train_loss: 0.203923, valid_loss: 0.138488\n",
      "train_f1: 0.704017, valid_f1: 0.782571\n",
      "--- 35.29043936729431 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000941387\n",
      "train_loss: 0.196696, valid_loss: 0.137958\n",
      "train_f1: 0.710734, valid_f1: 0.780589\n",
      "--- 35.420827865600586 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935802\n",
      "train_loss: 0.190601, valid_loss: 0.137986\n",
      "train_f1: 0.718588, valid_f1: 0.786957\n",
      "--- 35.76019072532654 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929980\n",
      "train_loss: 0.187396, valid_loss: 0.132143\n",
      "train_f1: 0.722811, valid_f1: 0.782913\n",
      "--- 34.511526584625244 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923926\n",
      "train_loss: 0.179563, valid_loss: 0.126022\n",
      "train_f1: 0.730662, valid_f1: 0.786324\n",
      "--- 33.04593276977539 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917642\n",
      "train_loss: 0.177905, valid_loss: 0.124106\n",
      "train_f1: 0.734223, valid_f1: 0.783411\n",
      "--- 35.77419590950012 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000911132\n",
      "train_loss: 0.173677, valid_loss: 0.118616\n",
      "train_f1: 0.736699, valid_f1: 0.792775\n",
      "--- 34.84910321235657 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000904400\n",
      "train_loss: 0.166905, valid_loss: 0.116273\n",
      "train_f1: 0.744698, valid_f1: 0.798742\n",
      "--- 35.02550196647644 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000897448\n",
      "train_loss: 0.170654, valid_loss: 0.120037\n",
      "train_f1: 0.744258, valid_f1: 0.795379\n",
      "--- 35.53485822677612 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000890282\n",
      "train_loss: 0.164969, valid_loss: 0.229288\n",
      "train_f1: 0.748729, valid_f1: 0.727049\n",
      "--- 35.58225226402283 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882903\n",
      "train_loss: 0.165030, valid_loss: 0.112743\n",
      "train_f1: 0.747761, valid_f1: 0.802564\n",
      "--- 35.36669564247131 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000875318\n",
      "train_loss: 0.156683, valid_loss: 0.109570\n",
      "train_f1: 0.755663, valid_f1: 0.802055\n",
      "--- 35.883708238601685 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000867529\n",
      "train_loss: 0.151918, valid_loss: 0.106590\n",
      "train_f1: 0.759254, valid_f1: 0.803431\n",
      "--- 35.473928689956665 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000859542\n",
      "train_loss: 0.148016, valid_loss: 0.105031\n",
      "train_f1: 0.765200, valid_f1: 0.802850\n",
      "--- 35.15251064300537 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000851359\n",
      "train_loss: 0.145237, valid_loss: 0.111821\n",
      "train_f1: 0.767390, valid_f1: 0.799294\n",
      "--- 35.51905608177185 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842986\n",
      "train_loss: 0.212491, valid_loss: 0.239956\n",
      "train_f1: 0.713598, valid_f1: 0.644167\n",
      "--- 35.17432761192322 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000834428\n",
      "train_loss: 0.190965, valid_loss: 0.118989\n",
      "train_f1: 0.705413, valid_f1: 0.795853\n",
      "--- 35.474130392074585 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000825689\n",
      "train_loss: 0.151130, valid_loss: 0.111254\n",
      "train_f1: 0.758284, valid_f1: 0.801151\n",
      "--- 35.15624666213989 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816773\n",
      "train_loss: 0.146007, valid_loss: 0.103923\n",
      "train_f1: 0.766037, valid_f1: 0.804923\n",
      "--- 35.55216693878174 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000807685\n",
      "train_loss: 0.142574, valid_loss: 0.103221\n",
      "train_f1: 0.770296, valid_f1: 0.805795\n",
      "--- 35.097593545913696 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000798431\n",
      "train_loss: 0.138635, valid_loss: 0.100956\n",
      "train_f1: 0.773694, valid_f1: 0.803976\n",
      "--- 34.97899556159973 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000789015\n",
      "train_loss: 0.135673, valid_loss: 0.100084\n",
      "train_f1: 0.775743, valid_f1: 0.805761\n",
      "--- 35.84561824798584 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000779443\n",
      "train_loss: 0.135905, valid_loss: 0.101764\n",
      "train_f1: 0.777746, valid_f1: 0.805896\n",
      "--- 35.34883213043213 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000769720\n",
      "train_loss: 0.169959, valid_loss: 0.103245\n",
      "train_f1: 0.746984, valid_f1: 0.804609\n",
      "--- 35.2200665473938 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759850\n",
      "train_loss: 0.135172, valid_loss: 0.100488\n",
      "train_f1: 0.778008, valid_f1: 0.808135\n",
      "--- 35.4630491733551 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000749840\n",
      "train_loss: 0.131730, valid_loss: 0.101577\n",
      "train_f1: 0.780742, valid_f1: 0.807155\n",
      "--- 35.89985370635986 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000739695\n",
      "train_loss: 0.128722, valid_loss: 0.096809\n",
      "train_f1: 0.784731, valid_f1: 0.807860\n",
      "--- 35.722156047821045 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000729419\n",
      "train_loss: 0.127318, valid_loss: 0.094615\n",
      "train_f1: 0.786003, valid_f1: 0.811579\n",
      "--- 35.59577035903931 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000719020\n",
      "train_loss: 0.126058, valid_loss: 0.096113\n",
      "train_f1: 0.788695, valid_f1: 0.813985\n",
      "--- 35.17926239967346 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000708501\n",
      "train_loss: 0.124884, valid_loss: 0.093127\n",
      "train_f1: 0.790800, valid_f1: 0.815346\n",
      "--- 34.97294068336487 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000697870\n",
      "train_loss: 0.122686, valid_loss: 0.095151\n",
      "train_f1: 0.791893, valid_f1: 0.813231\n",
      "--- 35.817786693573 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000687132\n",
      "train_loss: 0.121730, valid_loss: 0.091468\n",
      "train_f1: 0.792981, valid_f1: 0.816579\n",
      "--- 35.24185061454773 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000676292\n",
      "train_loss: 0.123230, valid_loss: 0.091354\n",
      "train_f1: 0.793839, valid_f1: 0.816954\n",
      "--- 35.39585828781128 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000665357\n",
      "train_loss: 0.119882, valid_loss: 0.092144\n",
      "train_f1: 0.798385, valid_f1: 0.815062\n",
      "--- 35.05281972885132 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000654333\n",
      "train_loss: 0.118018, valid_loss: 0.092212\n",
      "train_f1: 0.800292, valid_f1: 0.815396\n",
      "--- 35.1363263130188 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000643225\n",
      "train_loss: 0.119835, valid_loss: 0.091096\n",
      "train_f1: 0.798467, valid_f1: 0.816300\n",
      "--- 35.49524927139282 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000632039\n",
      "train_loss: 0.116910, valid_loss: 0.093621\n",
      "train_f1: 0.801706, valid_f1: 0.816005\n",
      "--- 35.00041079521179 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000620782\n",
      "train_loss: 0.117198, valid_loss: 0.088097\n",
      "train_f1: 0.804982, valid_f1: 0.818658\n",
      "--- 35.3243043422699 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000609459\n",
      "train_loss: 0.114733, valid_loss: 0.089163\n",
      "train_f1: 0.808754, valid_f1: 0.818500\n",
      "--- 35.38666820526123 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000598077\n",
      "train_loss: 0.115092, valid_loss: 0.086545\n",
      "train_f1: 0.810276, valid_f1: 0.819252\n",
      "--- 36.001126766204834 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000586642\n",
      "train_loss: 0.113330, valid_loss: 0.087401\n",
      "train_f1: 0.813413, valid_f1: 0.823737\n",
      "--- 35.149834394454956 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000575160\n",
      "train_loss: 0.112510, valid_loss: 0.087827\n",
      "train_f1: 0.817033, valid_f1: 0.821999\n",
      "--- 35.09412407875061 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000563638\n",
      "train_loss: 0.111741, valid_loss: 0.088185\n",
      "train_f1: 0.818462, valid_f1: 0.825189\n",
      "--- 35.272547245025635 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000552081\n",
      "train_loss: 0.110780, valid_loss: 0.084040\n",
      "train_f1: 0.821329, valid_f1: 0.826437\n",
      "--- 35.83612942695618 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000540495\n",
      "train_loss: 0.111131, valid_loss: 0.084585\n",
      "train_f1: 0.823171, valid_f1: 0.827437\n",
      "--- 35.47023153305054 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000528888\n",
      "train_loss: 0.111373, valid_loss: 0.084109\n",
      "train_f1: 0.823936, valid_f1: 0.864402\n",
      "--- 35.2657105922699 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000517265\n",
      "train_loss: 0.109085, valid_loss: 0.085223\n",
      "train_f1: 0.827136, valid_f1: 0.866558\n",
      "--- 34.56288242340088 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000505633\n",
      "train_loss: 0.108061, valid_loss: 0.082131\n",
      "train_f1: 0.830837, valid_f1: 0.882824\n",
      "--- 35.28348231315613 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493998\n",
      "train_loss: 0.108015, valid_loss: 0.081883\n",
      "train_f1: 0.831836, valid_f1: 0.862956\n",
      "--- 35.17548131942749 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000482366\n",
      "train_loss: 0.106441, valid_loss: 0.084732\n",
      "train_f1: 0.833462, valid_f1: 0.882462\n",
      "--- 35.55261564254761 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000470743\n",
      "train_loss: 0.106705, valid_loss: 0.084771\n",
      "train_f1: 0.834312, valid_f1: 0.897691\n",
      "--- 35.38051676750183 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000459137\n",
      "train_loss: 0.107054, valid_loss: 0.082359\n",
      "train_f1: 0.835355, valid_f1: 0.897401\n",
      "--- 35.430760860443115 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000447552\n",
      "train_loss: 0.105595, valid_loss: 0.081088\n",
      "train_f1: 0.837794, valid_f1: 0.896379\n",
      "--- 36.03384971618652 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435996\n",
      "train_loss: 0.104461, valid_loss: 0.082641\n",
      "train_f1: 0.838764, valid_f1: 0.901947\n",
      "--- 35.062477827072144 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000424475\n",
      "train_loss: 0.109458, valid_loss: 0.080525\n",
      "train_f1: 0.838412, valid_f1: 0.897441\n",
      "--- 35.33298945426941 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412994\n",
      "train_loss: 0.103793, valid_loss: 0.080643\n",
      "train_f1: 0.843721, valid_f1: 0.903826\n",
      "--- 35.14364957809448 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000401561\n",
      "train_loss: 0.103195, valid_loss: 0.078589\n",
      "train_f1: 0.844252, valid_f1: 0.897806\n",
      "--- 34.71372437477112 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000390181\n",
      "train_loss: 0.103482, valid_loss: 0.083996\n",
      "train_f1: 0.844865, valid_f1: 0.901148\n",
      "--- 35.05690860748291 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000378860\n",
      "train_loss: 0.102500, valid_loss: 0.078235\n",
      "train_f1: 0.844573, valid_f1: 0.905086\n",
      "--- 35.40888738632202 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000367605\n",
      "train_loss: 0.101245, valid_loss: 0.078473\n",
      "train_f1: 0.848365, valid_f1: 0.905957\n",
      "--- 35.259673833847046 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000356422\n",
      "train_loss: 0.102102, valid_loss: 0.077493\n",
      "train_f1: 0.848087, valid_f1: 0.904304\n",
      "--- 35.56276726722717 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000345316\n",
      "train_loss: 0.101285, valid_loss: 0.080445\n",
      "train_f1: 0.849055, valid_f1: 0.901371\n",
      "--- 35.29536843299866 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000334294\n",
      "train_loss: 0.100624, valid_loss: 0.076788\n",
      "train_f1: 0.851024, valid_f1: 0.906243\n",
      "--- 35.66911029815674 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000323362\n",
      "train_loss: 0.100732, valid_loss: 0.083167\n",
      "train_f1: 0.851399, valid_f1: 0.900068\n",
      "--- 35.9114453792572 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000312526\n",
      "train_loss: 0.100052, valid_loss: 0.078443\n",
      "train_f1: 0.850618, valid_f1: 0.902592\n",
      "--- 35.63194966316223 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000301791\n",
      "train_loss: 0.099098, valid_loss: 0.077927\n",
      "train_f1: 0.853656, valid_f1: 0.907262\n",
      "--- 34.87859511375427 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000291163\n",
      "train_loss: 0.098569, valid_loss: 0.075955\n",
      "train_f1: 0.854065, valid_f1: 0.907791\n",
      "--- 34.69459676742554 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000280649\n",
      "train_loss: 0.097176, valid_loss: 0.075923\n",
      "train_f1: 0.856213, valid_f1: 0.906888\n",
      "--- 35.042534828186035 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000270253\n",
      "train_loss: 0.097455, valid_loss: 0.077746\n",
      "train_f1: 0.856834, valid_f1: 0.908771\n",
      "--- 35.62462830543518 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259981\n",
      "train_loss: 0.097742, valid_loss: 0.075821\n",
      "train_f1: 0.857311, valid_f1: 0.908329\n",
      "--- 35.525216817855835 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000249840\n",
      "train_loss: 0.097739, valid_loss: 0.075005\n",
      "train_f1: 0.857638, valid_f1: 0.909779\n",
      "--- 35.40556287765503 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239834\n",
      "train_loss: 0.097268, valid_loss: 0.075304\n",
      "train_f1: 0.858707, valid_f1: 0.910530\n",
      "--- 35.38401389122009 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229969\n",
      "train_loss: 0.097558, valid_loss: 0.075308\n",
      "train_f1: 0.858294, valid_f1: 0.909038\n",
      "--- 35.62601089477539 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.000220251\n",
      "train_loss: 0.096826, valid_loss: 0.076817\n",
      "train_f1: 0.859137, valid_f1: 0.908863\n",
      "--- 35.30776762962341 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.000210683\n",
      "train_loss: 0.096104, valid_loss: 0.075099\n",
      "train_f1: 0.860069, valid_f1: 0.910345\n",
      "--- 35.740458726882935 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.000201273\n",
      "train_loss: 0.096270, valid_loss: 0.075208\n",
      "train_f1: 0.859844, valid_f1: 0.909455\n",
      "--- 35.54403257369995 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.000192024\n",
      "train_loss: 0.095476, valid_loss: 0.074642\n",
      "train_f1: 0.862200, valid_f1: 0.911283\n",
      "--- 35.4878454208374 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.000182942\n",
      "train_loss: 0.096099, valid_loss: 0.073662\n",
      "train_f1: 0.861677, valid_f1: 0.911788\n",
      "--- 36.00699281692505 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.000174031\n",
      "train_loss: 0.094704, valid_loss: 0.075224\n",
      "train_f1: 0.862244, valid_f1: 0.910222\n",
      "--- 35.209049701690674 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.000165298\n",
      "train_loss: 0.094606, valid_loss: 0.074250\n",
      "train_f1: 0.862150, valid_f1: 0.911718\n",
      "--- 35.69839549064636 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.000156745\n",
      "train_loss: 0.094340, valid_loss: 0.074057\n",
      "train_f1: 0.863547, valid_f1: 0.911358\n",
      "--- 35.567999601364136 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.000148378\n",
      "train_loss: 0.094024, valid_loss: 0.073588\n",
      "train_f1: 0.864817, valid_f1: 0.912175\n",
      "--- 35.41336917877197 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.000140202\n",
      "train_loss: 0.094835, valid_loss: 0.073038\n",
      "train_f1: 0.864051, valid_f1: 0.912812\n",
      "--- 35.1358425617218 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.000132220\n",
      "train_loss: 0.093574, valid_loss: 0.073635\n",
      "train_f1: 0.865220, valid_f1: 0.912639\n",
      "--- 35.414977073669434 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.000124438\n",
      "train_loss: 0.093494, valid_loss: 0.073230\n",
      "train_f1: 0.865103, valid_f1: 0.912749\n",
      "--- 35.30959606170654 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.000116859\n",
      "train_loss: 0.093219, valid_loss: 0.073444\n",
      "train_f1: 0.865654, valid_f1: 0.910990\n",
      "--- 35.55776071548462 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.000109488\n",
      "train_loss: 0.092993, valid_loss: 0.073741\n",
      "train_f1: 0.865823, valid_f1: 0.912366\n",
      "--- 35.656872034072876 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.000102328\n",
      "train_loss: 0.093126, valid_loss: 0.073304\n",
      "train_f1: 0.866052, valid_f1: 0.912890\n",
      "--- 36.226974964141846 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000095383\n",
      "train_loss: 0.092464, valid_loss: 0.072752\n",
      "train_f1: 0.866123, valid_f1: 0.913379\n",
      "--- 35.57929825782776 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000088658\n",
      "train_loss: 0.093070, valid_loss: 0.072973\n",
      "train_f1: 0.866337, valid_f1: 0.913189\n",
      "--- 37.60596513748169 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000082155\n",
      "train_loss: 0.092598, valid_loss: 0.073017\n",
      "train_f1: 0.867437, valid_f1: 0.913714\n",
      "--- 38.34090995788574 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000075878\n",
      "train_loss: 0.092243, valid_loss: 0.073353\n",
      "train_f1: 0.867575, valid_f1: 0.913146\n",
      "--- 35.74356555938721 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000069831\n",
      "train_loss: 0.091879, valid_loss: 0.072530\n",
      "train_f1: 0.867899, valid_f1: 0.913200\n",
      "--- 35.865822553634644 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000064017\n",
      "train_loss: 0.092200, valid_loss: 0.073403\n",
      "train_f1: 0.868020, valid_f1: 0.912564\n",
      "--- 36.0177686214447 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000058440\n",
      "train_loss: 0.091970, valid_loss: 0.072746\n",
      "train_f1: 0.868549, valid_f1: 0.913584\n",
      "--- 37.23429298400879 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000053101\n",
      "train_loss: 0.092118, valid_loss: 0.072445\n",
      "train_f1: 0.867901, valid_f1: 0.913665\n",
      "--- 36.45885634422302 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000048004\n",
      "train_loss: 0.092540, valid_loss: 0.072640\n",
      "train_f1: 0.868722, valid_f1: 0.912780\n",
      "--- 37.503706216812134 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000043152\n",
      "train_loss: 0.092155, valid_loss: 0.072796\n",
      "train_f1: 0.868736, valid_f1: 0.913510\n",
      "--- 35.11201548576355 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000038548\n",
      "train_loss: 0.092287, valid_loss: 0.072503\n",
      "train_f1: 0.868678, valid_f1: 0.913898\n",
      "--- 32.64198064804077 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000034193\n",
      "train_loss: 0.091983, valid_loss: 0.072177\n",
      "train_f1: 0.868481, valid_f1: 0.914208\n",
      "--- 34.6156210899353 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000030091\n",
      "train_loss: 0.091494, valid_loss: 0.072308\n",
      "train_f1: 0.868289, valid_f1: 0.913975\n",
      "--- 32.84868311882019 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000026243\n",
      "train_loss: 0.092254, valid_loss: 0.072209\n",
      "train_f1: 0.869451, valid_f1: 0.914207\n",
      "--- 33.54025840759277 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000022651\n",
      "train_loss: 0.091570, valid_loss: 0.072391\n",
      "train_f1: 0.869046, valid_f1: 0.914044\n",
      "--- 33.7761287689209 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000019318\n",
      "train_loss: 0.090948, valid_loss: 0.072465\n",
      "train_f1: 0.869241, valid_f1: 0.913762\n",
      "--- 32.72686290740967 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000016246\n",
      "train_loss: 0.091721, valid_loss: 0.072166\n",
      "train_f1: 0.869349, valid_f1: 0.914173\n",
      "--- 33.839425802230835 seconds ---\n",
      "Epoch : 140\n",
      "learning_rate: 0.000013435\n",
      "train_loss: 0.090870, valid_loss: 0.072208\n",
      "train_f1: 0.869278, valid_f1: 0.914018\n",
      "--- 32.452484369277954 seconds ---\n",
      "Epoch : 141\n",
      "learning_rate: 0.000010888\n",
      "train_loss: 0.091548, valid_loss: 0.072237\n",
      "train_f1: 0.869429, valid_f1: 0.913910\n",
      "--- 34.91284227371216 seconds ---\n",
      "Epoch : 142\n",
      "learning_rate: 0.000008606\n",
      "train_loss: 0.091694, valid_loss: 0.072208\n",
      "train_f1: 0.869609, valid_f1: 0.914083\n",
      "--- 38.70294761657715 seconds ---\n",
      "Epoch : 143\n",
      "learning_rate: 0.000006589\n",
      "train_loss: 0.091272, valid_loss: 0.072163\n",
      "train_f1: 0.869145, valid_f1: 0.914095\n",
      "--- 37.394453048706055 seconds ---\n",
      "Epoch : 144\n",
      "learning_rate: 0.000004840\n",
      "train_loss: 0.090899, valid_loss: 0.072216\n",
      "train_f1: 0.869653, valid_f1: 0.914040\n",
      "--- 39.26647734642029 seconds ---\n",
      "Epoch : 145\n",
      "learning_rate: 0.000003360\n",
      "train_loss: 0.091827, valid_loss: 0.072221\n",
      "train_f1: 0.869920, valid_f1: 0.914044\n",
      "--- 37.562068939208984 seconds ---\n",
      "Epoch : 146\n",
      "learning_rate: 0.000002148\n",
      "train_loss: 0.091432, valid_loss: 0.072198\n",
      "train_f1: 0.869143, valid_f1: 0.914016\n",
      "--- 38.24841547012329 seconds ---\n",
      "Epoch : 147\n",
      "learning_rate: 0.000001205\n",
      "train_loss: 0.091579, valid_loss: 0.072188\n",
      "train_f1: 0.869533, valid_f1: 0.914025\n",
      "--- 38.292102098464966 seconds ---\n",
      "Epoch : 148\n",
      "learning_rate: 0.000000533\n",
      "train_loss: 0.091072, valid_loss: 0.072190\n",
      "train_f1: 0.869715, valid_f1: 0.914020\n",
      "--- 38.035908222198486 seconds ---\n",
      "Epoch : 149\n",
      "learning_rate: 0.000000131\n",
      "train_loss: 0.091244, valid_loss: 0.072188\n",
      "train_f1: 0.869382, valid_f1: 0.914023\n",
      "--- 37.54432415962219 seconds ---\n",
      "Fold : 1\n",
      "Epoch : 0\n",
      "learning_rate: 0.000001000\n",
      "train_loss: 2.204003, valid_loss: 1.915934\n",
      "train_f1: 0.067043, valid_f1: 0.027787\n",
      "--- 38.14479660987854 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000011938\n",
      "train_loss: 2.028630, valid_loss: 1.735507\n",
      "train_f1: 0.070717, valid_f1: 0.021731\n",
      "--- 39.64272141456604 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000044274\n",
      "train_loss: 1.748139, valid_loss: 1.472367\n",
      "train_f1: 0.081377, valid_f1: 0.035429\n",
      "--- 38.88495588302612 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000096592\n",
      "train_loss: 1.412801, valid_loss: 0.962624\n",
      "train_f1: 0.098824, valid_f1: 0.066464\n",
      "--- 38.3663284778595 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000166599\n",
      "train_loss: 1.054339, valid_loss: 0.735592\n",
      "train_f1: 0.127498, valid_f1: 0.128469\n",
      "--- 37.16421413421631 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000251230\n",
      "train_loss: 0.854233, valid_loss: 0.654998\n",
      "train_f1: 0.158811, valid_f1: 0.149459\n",
      "--- 38.671367168426514 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000346779\n",
      "train_loss: 0.755881, valid_loss: 0.618758\n",
      "train_f1: 0.183217, valid_f1: 0.184972\n",
      "--- 38.76189041137695 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000449060\n",
      "train_loss: 0.696333, valid_loss: 0.581143\n",
      "train_f1: 0.201859, valid_f1: 0.179894\n",
      "--- 38.87950825691223 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000553594\n",
      "train_loss: 0.657889, valid_loss: 0.576554\n",
      "train_f1: 0.213326, valid_f1: 0.191460\n",
      "--- 39.11899375915527 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000655802\n",
      "train_loss: 0.630220, valid_loss: 0.557591\n",
      "train_f1: 0.225588, valid_f1: 0.267418\n",
      "--- 37.92242240905762 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000751209\n",
      "train_loss: 0.606478, valid_loss: 0.528392\n",
      "train_f1: 0.241876, valid_f1: 0.286170\n",
      "--- 38.79470896720886 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000835636\n",
      "train_loss: 0.580787, valid_loss: 0.497236\n",
      "train_f1: 0.264888, valid_f1: 0.310189\n",
      "--- 38.636483907699585 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000905384\n",
      "train_loss: 0.549606, valid_loss: 0.478568\n",
      "train_f1: 0.292934, valid_f1: 0.309923\n",
      "--- 38.249622106552124 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000957400\n",
      "train_loss: 0.522636, valid_loss: 0.431088\n",
      "train_f1: 0.317267, valid_f1: 0.406236\n",
      "--- 38.08592867851257 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000989405\n",
      "train_loss: 0.488584, valid_loss: 0.383966\n",
      "train_f1: 0.353352, valid_f1: 0.427830\n",
      "--- 37.99843764305115 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.001000000\n",
      "train_loss: 0.454952, valid_loss: 0.359092\n",
      "train_f1: 0.388262, valid_f1: 0.436610\n",
      "--- 38.15811228752136 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999860\n",
      "train_loss: 0.419342, valid_loss: 0.312441\n",
      "train_f1: 0.429311, valid_f1: 0.508993\n",
      "--- 38.64319372177124 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999450\n",
      "train_loss: 0.392465, valid_loss: 0.292218\n",
      "train_f1: 0.466858, valid_f1: 0.563515\n",
      "--- 37.39116382598877 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998769\n",
      "train_loss: 0.373582, valid_loss: 0.286602\n",
      "train_f1: 0.488566, valid_f1: 0.616566\n",
      "--- 38.532012939453125 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997818\n",
      "train_loss: 0.349606, valid_loss: 0.252156\n",
      "train_f1: 0.522140, valid_f1: 0.620438\n",
      "--- 38.426674604415894 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996598\n",
      "train_loss: 0.324813, valid_loss: 0.269152\n",
      "train_f1: 0.550860, valid_f1: 0.552679\n",
      "--- 37.51348805427551 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000995108\n",
      "train_loss: 0.309423, valid_loss: 0.221722\n",
      "train_f1: 0.565351, valid_f1: 0.693743\n",
      "--- 38.18758487701416 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993351\n",
      "train_loss: 0.299539, valid_loss: 0.206901\n",
      "train_f1: 0.578676, valid_f1: 0.710903\n",
      "--- 38.38557958602905 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991326\n",
      "train_loss: 0.280917, valid_loss: 0.193120\n",
      "train_f1: 0.602658, valid_f1: 0.724658\n",
      "--- 38.58057904243469 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000989035\n",
      "train_loss: 0.269747, valid_loss: 0.189714\n",
      "train_f1: 0.613256, valid_f1: 0.736754\n",
      "--- 37.69627261161804 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986480\n",
      "train_loss: 0.255377, valid_loss: 0.179971\n",
      "train_f1: 0.633328, valid_f1: 0.737697\n",
      "--- 38.24144220352173 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983661\n",
      "train_loss: 0.248756, valid_loss: 0.181512\n",
      "train_f1: 0.641388, valid_f1: 0.720911\n",
      "--- 38.19507169723511 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980580\n",
      "train_loss: 0.247385, valid_loss: 0.177025\n",
      "train_f1: 0.649278, valid_f1: 0.744210\n",
      "--- 38.2844352722168 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000977239\n",
      "train_loss: 0.226468, valid_loss: 0.153298\n",
      "train_f1: 0.674296, valid_f1: 0.765924\n",
      "--- 32.44313836097717 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973639\n",
      "train_loss: 0.217906, valid_loss: 0.145330\n",
      "train_f1: 0.680839, valid_f1: 0.773527\n",
      "--- 32.27166485786438 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969783\n",
      "train_loss: 0.217163, valid_loss: 0.153751\n",
      "train_f1: 0.689266, valid_f1: 0.761952\n",
      "--- 32.31379675865173 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965673\n",
      "train_loss: 0.204528, valid_loss: 0.140199\n",
      "train_f1: 0.700500, valid_f1: 0.776844\n",
      "--- 32.28564691543579 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000961310\n",
      "train_loss: 0.198272, valid_loss: 0.136111\n",
      "train_f1: 0.706384, valid_f1: 0.765236\n",
      "--- 32.68810677528381 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956698\n",
      "train_loss: 0.190304, valid_loss: 0.126226\n",
      "train_f1: 0.716129, valid_f1: 0.785674\n",
      "--- 32.58964490890503 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951838\n",
      "train_loss: 0.201918, valid_loss: 0.132992\n",
      "train_f1: 0.717248, valid_f1: 0.783930\n",
      "--- 32.19746375083923 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946733\n",
      "train_loss: 0.188958, valid_loss: 0.125970\n",
      "train_f1: 0.724912, valid_f1: 0.785187\n",
      "--- 32.51492381095886 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000941387\n",
      "train_loss: 0.177424, valid_loss: 0.126502\n",
      "train_f1: 0.733609, valid_f1: 0.781160\n",
      "--- 32.65246295928955 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935802\n",
      "train_loss: 0.173371, valid_loss: 0.119818\n",
      "train_f1: 0.737281, valid_f1: 0.789716\n",
      "--- 32.34061288833618 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929980\n",
      "train_loss: 0.165461, valid_loss: 0.116480\n",
      "train_f1: 0.743123, valid_f1: 0.777642\n",
      "--- 32.23370122909546 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923926\n",
      "train_loss: 0.161592, valid_loss: 0.112664\n",
      "train_f1: 0.748089, valid_f1: 0.795121\n",
      "--- 32.137341260910034 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917642\n",
      "train_loss: 0.160495, valid_loss: 0.109735\n",
      "train_f1: 0.749389, valid_f1: 0.791015\n",
      "--- 32.19970893859863 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000911132\n",
      "train_loss: 0.158968, valid_loss: 0.109021\n",
      "train_f1: 0.751003, valid_f1: 0.794484\n",
      "--- 32.69227719306946 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000904400\n",
      "train_loss: 0.151365, valid_loss: 0.106916\n",
      "train_f1: 0.759236, valid_f1: 0.788649\n",
      "--- 31.778685092926025 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000897448\n",
      "train_loss: 0.146955, valid_loss: 0.102757\n",
      "train_f1: 0.762686, valid_f1: 0.802269\n",
      "--- 32.22151708602905 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000890282\n",
      "train_loss: 0.143118, valid_loss: 0.101680\n",
      "train_f1: 0.767325, valid_f1: 0.801532\n",
      "--- 32.52835035324097 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882903\n",
      "train_loss: 0.146182, valid_loss: 0.103607\n",
      "train_f1: 0.763473, valid_f1: 0.792916\n",
      "--- 33.15929102897644 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000875318\n",
      "train_loss: 0.143498, valid_loss: 0.105370\n",
      "train_f1: 0.767168, valid_f1: 0.802166\n",
      "--- 32.85462999343872 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000867529\n",
      "train_loss: 0.149123, valid_loss: 0.163229\n",
      "train_f1: 0.766948, valid_f1: 0.772619\n",
      "--- 32.36423373222351 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000859542\n",
      "train_loss: 0.178514, valid_loss: 0.102508\n",
      "train_f1: 0.734210, valid_f1: 0.800460\n",
      "--- 32.69986009597778 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000851359\n",
      "train_loss: 0.142589, valid_loss: 0.099684\n",
      "train_f1: 0.767387, valid_f1: 0.800724\n",
      "--- 31.697003841400146 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842986\n",
      "train_loss: 0.139171, valid_loss: 0.097953\n",
      "train_f1: 0.773286, valid_f1: 0.803282\n",
      "--- 32.121572732925415 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000834428\n",
      "train_loss: 0.134654, valid_loss: 0.095020\n",
      "train_f1: 0.776777, valid_f1: 0.808236\n",
      "--- 32.12986350059509 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000825689\n",
      "train_loss: 0.131075, valid_loss: 0.093065\n",
      "train_f1: 0.781140, valid_f1: 0.810212\n",
      "--- 32.61530613899231 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816773\n",
      "train_loss: 0.128068, valid_loss: 0.093990\n",
      "train_f1: 0.782834, valid_f1: 0.809768\n",
      "--- 32.52189588546753 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000807685\n",
      "train_loss: 0.127452, valid_loss: 0.090340\n",
      "train_f1: 0.784275, valid_f1: 0.812073\n",
      "--- 32.079103231430054 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000798431\n",
      "train_loss: 0.126055, valid_loss: 0.089871\n",
      "train_f1: 0.784170, valid_f1: 0.809796\n",
      "--- 32.83853030204773 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000789015\n",
      "train_loss: 0.123812, valid_loss: 0.090619\n",
      "train_f1: 0.787798, valid_f1: 0.811090\n",
      "--- 32.98486399650574 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000779443\n",
      "train_loss: 0.122613, valid_loss: 0.087937\n",
      "train_f1: 0.787641, valid_f1: 0.813392\n",
      "--- 32.289947748184204 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000769720\n",
      "train_loss: 0.120918, valid_loss: 0.087181\n",
      "train_f1: 0.790057, valid_f1: 0.811915\n",
      "--- 31.898152589797974 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759850\n",
      "train_loss: 0.120868, valid_loss: 0.086846\n",
      "train_f1: 0.790476, valid_f1: 0.815139\n",
      "--- 32.890746116638184 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000749840\n",
      "train_loss: 0.119305, valid_loss: 0.093040\n",
      "train_f1: 0.791350, valid_f1: 0.810801\n",
      "--- 32.226330280303955 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000739695\n",
      "train_loss: 0.117889, valid_loss: 0.085717\n",
      "train_f1: 0.793263, valid_f1: 0.812797\n",
      "--- 32.1949577331543 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000729419\n",
      "train_loss: 0.117897, valid_loss: 0.090307\n",
      "train_f1: 0.794784, valid_f1: 0.810146\n",
      "--- 32.34891653060913 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000719020\n",
      "train_loss: 0.117946, valid_loss: 0.085431\n",
      "train_f1: 0.794468, valid_f1: 0.816580\n",
      "--- 33.58424258232117 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000708501\n",
      "train_loss: 0.115593, valid_loss: 0.084199\n",
      "train_f1: 0.797416, valid_f1: 0.817844\n",
      "--- 32.12494516372681 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000697870\n",
      "train_loss: 0.113668, valid_loss: 0.083460\n",
      "train_f1: 0.801357, valid_f1: 0.818665\n",
      "--- 32.16110920906067 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000687132\n",
      "train_loss: 0.112256, valid_loss: 0.084794\n",
      "train_f1: 0.805328, valid_f1: 0.818180\n",
      "--- 32.15488958358765 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000676292\n",
      "train_loss: 0.112705, valid_loss: 0.081703\n",
      "train_f1: 0.806443, valid_f1: 0.820806\n",
      "--- 32.61941933631897 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000665357\n",
      "train_loss: 0.110586, valid_loss: 0.081133\n",
      "train_f1: 0.809797, valid_f1: 0.819088\n",
      "--- 32.44961762428284 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000654333\n",
      "train_loss: 0.111195, valid_loss: 0.082000\n",
      "train_f1: 0.812588, valid_f1: 0.818104\n",
      "--- 32.04749917984009 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000643225\n",
      "train_loss: 0.109868, valid_loss: 0.080189\n",
      "train_f1: 0.817896, valid_f1: 0.822209\n",
      "--- 32.183347940444946 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000632039\n",
      "train_loss: 0.107231, valid_loss: 0.078506\n",
      "train_f1: 0.825644, valid_f1: 0.828342\n",
      "--- 32.71688508987427 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000620782\n",
      "train_loss: 0.107028, valid_loss: 0.079170\n",
      "train_f1: 0.830107, valid_f1: 0.873125\n",
      "--- 32.49276304244995 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000609459\n",
      "train_loss: 0.108167, valid_loss: 0.077794\n",
      "train_f1: 0.833190, valid_f1: 0.879461\n",
      "--- 32.87918400764465 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000598077\n",
      "train_loss: 0.106634, valid_loss: 0.079167\n",
      "train_f1: 0.838961, valid_f1: 0.880022\n",
      "--- 33.343212842941284 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000586642\n",
      "train_loss: 0.107445, valid_loss: 0.077795\n",
      "train_f1: 0.837638, valid_f1: 0.890459\n",
      "--- 32.93386268615723 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000575160\n",
      "train_loss: 0.105673, valid_loss: 0.077809\n",
      "train_f1: 0.840106, valid_f1: 0.897768\n",
      "--- 32.33003044128418 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000563638\n",
      "train_loss: 0.105082, valid_loss: 0.077800\n",
      "train_f1: 0.845480, valid_f1: 0.895733\n",
      "--- 31.141953229904175 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000552081\n",
      "train_loss: 0.103266, valid_loss: 0.079193\n",
      "train_f1: 0.848301, valid_f1: 0.887791\n",
      "--- 32.464675188064575 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000540495\n",
      "train_loss: 0.101748, valid_loss: 0.075629\n",
      "train_f1: 0.851012, valid_f1: 0.895767\n",
      "--- 32.26608347892761 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000528888\n",
      "train_loss: 0.101342, valid_loss: 0.075647\n",
      "train_f1: 0.853379, valid_f1: 0.898481\n",
      "--- 32.12948155403137 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000517265\n",
      "train_loss: 0.101645, valid_loss: 0.081668\n",
      "train_f1: 0.854673, valid_f1: 0.881601\n",
      "--- 33.2034707069397 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000505633\n",
      "train_loss: 0.102082, valid_loss: 0.076514\n",
      "train_f1: 0.853489, valid_f1: 0.894936\n",
      "--- 32.923821449279785 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493998\n",
      "train_loss: 0.099274, valid_loss: 0.074043\n",
      "train_f1: 0.858195, valid_f1: 0.901574\n",
      "--- 33.03369140625 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000482366\n",
      "train_loss: 0.100306, valid_loss: 0.075163\n",
      "train_f1: 0.858004, valid_f1: 0.899042\n",
      "--- 32.60101890563965 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000470743\n",
      "train_loss: 0.098423, valid_loss: 0.072716\n",
      "train_f1: 0.861607, valid_f1: 0.906666\n",
      "--- 32.535649061203 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000459137\n",
      "train_loss: 0.098212, valid_loss: 0.074375\n",
      "train_f1: 0.863524, valid_f1: 0.899439\n",
      "--- 32.09235644340515 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000447552\n",
      "train_loss: 0.098496, valid_loss: 0.072917\n",
      "train_f1: 0.862556, valid_f1: 0.903704\n",
      "--- 31.556909799575806 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435996\n",
      "train_loss: 0.097957, valid_loss: 0.077443\n",
      "train_f1: 0.863803, valid_f1: 0.892301\n",
      "--- 31.29250693321228 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000424475\n",
      "train_loss: 0.097665, valid_loss: 0.073281\n",
      "train_f1: 0.863114, valid_f1: 0.903911\n",
      "--- 32.13497233390808 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412994\n",
      "train_loss: 0.096429, valid_loss: 0.076172\n",
      "train_f1: 0.867024, valid_f1: 0.896081\n",
      "--- 32.68238592147827 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000401561\n",
      "train_loss: 0.098414, valid_loss: 0.078336\n",
      "train_f1: 0.865946, valid_f1: 0.896844\n",
      "--- 32.66640305519104 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000390181\n",
      "train_loss: 0.100249, valid_loss: 0.071953\n",
      "train_f1: 0.864559, valid_f1: 0.906315\n",
      "--- 32.533007860183716 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000378860\n",
      "train_loss: 0.095571, valid_loss: 0.071663\n",
      "train_f1: 0.868785, valid_f1: 0.907846\n",
      "--- 33.41405391693115 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000367605\n",
      "train_loss: 0.094872, valid_loss: 0.071180\n",
      "train_f1: 0.868744, valid_f1: 0.908646\n",
      "--- 32.66626310348511 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000356422\n",
      "train_loss: 0.093839, valid_loss: 0.073200\n",
      "train_f1: 0.871315, valid_f1: 0.903471\n",
      "--- 32.43834638595581 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000345316\n",
      "train_loss: 0.094824, valid_loss: 0.072641\n",
      "train_f1: 0.869259, valid_f1: 0.903365\n",
      "--- 32.77184343338013 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000334294\n",
      "train_loss: 0.094078, valid_loss: 0.071071\n",
      "train_f1: 0.870341, valid_f1: 0.908601\n",
      "--- 31.951053619384766 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000323362\n",
      "train_loss: 0.093136, valid_loss: 0.069623\n",
      "train_f1: 0.872310, valid_f1: 0.910744\n",
      "--- 31.51090407371521 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000312526\n",
      "train_loss: 0.092332, valid_loss: 0.076124\n",
      "train_f1: 0.874298, valid_f1: 0.896441\n",
      "--- 32.626736640930176 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000301791\n",
      "train_loss: 0.093820, valid_loss: 0.070482\n",
      "train_f1: 0.873365, valid_f1: 0.910178\n",
      "--- 32.44485950469971 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000291163\n",
      "train_loss: 0.092163, valid_loss: 0.069470\n",
      "train_f1: 0.874580, valid_f1: 0.910874\n",
      "--- 32.450215101242065 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000280649\n",
      "train_loss: 0.091915, valid_loss: 0.069790\n",
      "train_f1: 0.875192, valid_f1: 0.910575\n",
      "--- 32.166425943374634 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000270253\n",
      "train_loss: 0.091851, valid_loss: 0.069839\n",
      "train_f1: 0.874804, valid_f1: 0.909583\n",
      "--- 32.28228163719177 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259981\n",
      "train_loss: 0.091920, valid_loss: 0.069261\n",
      "train_f1: 0.875321, valid_f1: 0.911507\n",
      "--- 32.42017126083374 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000249840\n",
      "train_loss: 0.091019, valid_loss: 0.069249\n",
      "train_f1: 0.876804, valid_f1: 0.911131\n",
      "--- 31.175827980041504 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239834\n",
      "train_loss: 0.090642, valid_loss: 0.068831\n",
      "train_f1: 0.876837, valid_f1: 0.912273\n",
      "--- 33.015380859375 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229969\n",
      "train_loss: 0.089972, valid_loss: 0.068374\n",
      "train_f1: 0.878409, valid_f1: 0.911956\n",
      "--- 32.20777678489685 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.000220251\n",
      "train_loss: 0.090110, valid_loss: 0.067971\n",
      "train_f1: 0.878564, valid_f1: 0.912768\n",
      "--- 32.163665771484375 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.000210683\n",
      "train_loss: 0.089894, valid_loss: 0.068353\n",
      "train_f1: 0.879118, valid_f1: 0.912621\n",
      "--- 32.86476540565491 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.000201273\n",
      "train_loss: 0.089372, valid_loss: 0.068273\n",
      "train_f1: 0.878604, valid_f1: 0.912823\n",
      "--- 32.57501792907715 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.000192024\n",
      "train_loss: 0.089288, valid_loss: 0.068238\n",
      "train_f1: 0.879032, valid_f1: 0.912920\n",
      "--- 32.55175185203552 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.000182942\n",
      "train_loss: 0.089381, valid_loss: 0.069053\n",
      "train_f1: 0.878769, valid_f1: 0.911777\n",
      "--- 31.95609188079834 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.000174031\n",
      "train_loss: 0.090792, valid_loss: 0.068984\n",
      "train_f1: 0.877770, valid_f1: 0.910682\n",
      "--- 32.32797980308533 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.000165298\n",
      "train_loss: 0.089751, valid_loss: 0.067750\n",
      "train_f1: 0.879456, valid_f1: 0.913160\n",
      "--- 31.573882579803467 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.000156745\n",
      "train_loss: 0.088863, valid_loss: 0.067735\n",
      "train_f1: 0.881056, valid_f1: 0.913017\n",
      "--- 32.309364318847656 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.000148378\n",
      "train_loss: 0.088210, valid_loss: 0.069223\n",
      "train_f1: 0.881396, valid_f1: 0.909301\n",
      "--- 32.51244926452637 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.000140202\n",
      "train_loss: 0.088683, valid_loss: 0.067391\n",
      "train_f1: 0.881121, valid_f1: 0.913412\n",
      "--- 32.17847156524658 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.000132220\n",
      "train_loss: 0.088481, valid_loss: 0.067736\n",
      "train_f1: 0.881657, valid_f1: 0.911710\n",
      "--- 32.0722599029541 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.000124438\n",
      "train_loss: 0.087967, valid_loss: 0.067299\n",
      "train_f1: 0.882133, valid_f1: 0.913134\n",
      "--- 32.42437267303467 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.000116859\n",
      "train_loss: 0.088132, valid_loss: 0.067267\n",
      "train_f1: 0.881996, valid_f1: 0.913756\n",
      "--- 32.39087533950806 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.000109488\n",
      "train_loss: 0.087213, valid_loss: 0.067993\n",
      "train_f1: 0.882677, valid_f1: 0.911796\n",
      "--- 32.18419933319092 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.000102328\n",
      "train_loss: 0.087546, valid_loss: 0.066926\n",
      "train_f1: 0.882291, valid_f1: 0.913912\n",
      "--- 32.44438886642456 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000095383\n",
      "train_loss: 0.087246, valid_loss: 0.066883\n",
      "train_f1: 0.882796, valid_f1: 0.914047\n",
      "--- 32.14659881591797 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000088658\n",
      "train_loss: 0.086918, valid_loss: 0.067003\n",
      "train_f1: 0.882963, valid_f1: 0.914113\n",
      "--- 32.62914538383484 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000082155\n",
      "train_loss: 0.087298, valid_loss: 0.067695\n",
      "train_f1: 0.883402, valid_f1: 0.912357\n",
      "--- 33.19360113143921 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000075878\n",
      "train_loss: 0.087431, valid_loss: 0.067079\n",
      "train_f1: 0.882958, valid_f1: 0.913559\n",
      "--- 32.20577430725098 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000069831\n",
      "train_loss: 0.087133, valid_loss: 0.066845\n",
      "train_f1: 0.883957, valid_f1: 0.913798\n",
      "--- 32.53854489326477 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000064017\n",
      "train_loss: 0.087209, valid_loss: 0.066409\n",
      "train_f1: 0.883476, valid_f1: 0.914475\n",
      "--- 34.13985085487366 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000058440\n",
      "train_loss: 0.086821, valid_loss: 0.067098\n",
      "train_f1: 0.884395, valid_f1: 0.913260\n",
      "--- 34.9861044883728 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000053101\n",
      "train_loss: 0.086542, valid_loss: 0.066583\n",
      "train_f1: 0.884041, valid_f1: 0.914074\n",
      "--- 32.48302245140076 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000048004\n",
      "train_loss: 0.086541, valid_loss: 0.066467\n",
      "train_f1: 0.884266, valid_f1: 0.914718\n",
      "--- 32.74292612075806 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000043152\n",
      "train_loss: 0.086053, valid_loss: 0.067010\n",
      "train_f1: 0.883762, valid_f1: 0.913545\n",
      "--- 32.3819842338562 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000038548\n",
      "train_loss: 0.086536, valid_loss: 0.066627\n",
      "train_f1: 0.884057, valid_f1: 0.913950\n",
      "--- 32.319215297698975 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000034193\n",
      "train_loss: 0.086362, valid_loss: 0.066684\n",
      "train_f1: 0.884519, valid_f1: 0.913968\n",
      "--- 32.80057382583618 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000030091\n",
      "train_loss: 0.085449, valid_loss: 0.066286\n",
      "train_f1: 0.884947, valid_f1: 0.914768\n",
      "--- 32.32428598403931 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000026243\n",
      "train_loss: 0.086212, valid_loss: 0.066737\n",
      "train_f1: 0.885074, valid_f1: 0.913748\n",
      "--- 32.30787777900696 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000022651\n",
      "train_loss: 0.086391, valid_loss: 0.066374\n",
      "train_f1: 0.884881, valid_f1: 0.914714\n",
      "--- 32.289167165756226 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000019318\n",
      "train_loss: 0.085941, valid_loss: 0.066392\n",
      "train_f1: 0.884646, valid_f1: 0.914749\n",
      "--- 32.428488969802856 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000016246\n",
      "train_loss: 0.085846, valid_loss: 0.066465\n",
      "train_f1: 0.885253, valid_f1: 0.914373\n",
      "--- 32.115679025650024 seconds ---\n",
      "Epoch : 140\n",
      "learning_rate: 0.000013435\n",
      "train_loss: 0.085663, valid_loss: 0.066499\n",
      "train_f1: 0.885060, valid_f1: 0.914202\n",
      "--- 32.03692579269409 seconds ---\n",
      "Epoch : 141\n",
      "learning_rate: 0.000010888\n",
      "train_loss: 0.086228, valid_loss: 0.066495\n",
      "train_f1: 0.885394, valid_f1: 0.914256\n",
      "--- 32.161964654922485 seconds ---\n",
      "Epoch : 142\n",
      "learning_rate: 0.000008606\n",
      "train_loss: 0.085696, valid_loss: 0.066465\n",
      "train_f1: 0.885233, valid_f1: 0.914300\n",
      "--- 32.26280450820923 seconds ---\n",
      "Epoch : 143\n",
      "learning_rate: 0.000006589\n",
      "train_loss: 0.085401, valid_loss: 0.066431\n",
      "train_f1: 0.885238, valid_f1: 0.914356\n",
      "--- 32.01476740837097 seconds ---\n",
      "Epoch : 144\n",
      "learning_rate: 0.000004840\n",
      "train_loss: 0.085781, valid_loss: 0.066393\n",
      "train_f1: 0.885153, valid_f1: 0.914384\n",
      "--- 31.59451961517334 seconds ---\n",
      "Epoch : 145\n",
      "learning_rate: 0.000003360\n",
      "train_loss: 0.086075, valid_loss: 0.066397\n",
      "train_f1: 0.885435, valid_f1: 0.914346\n",
      "--- 31.68127727508545 seconds ---\n",
      "Epoch : 146\n",
      "learning_rate: 0.000002148\n",
      "train_loss: 0.085735, valid_loss: 0.066416\n",
      "train_f1: 0.885263, valid_f1: 0.914348\n",
      "--- 32.12204027175903 seconds ---\n",
      "Epoch : 147\n",
      "learning_rate: 0.000001205\n",
      "train_loss: 0.085658, valid_loss: 0.066406\n",
      "train_f1: 0.885374, valid_f1: 0.914379\n",
      "--- 32.479275703430176 seconds ---\n",
      "Epoch : 148\n",
      "learning_rate: 0.000000533\n",
      "train_loss: 0.085948, valid_loss: 0.066410\n",
      "train_f1: 0.884849, valid_f1: 0.914363\n",
      "--- 32.23148155212402 seconds ---\n",
      "Epoch : 149\n",
      "learning_rate: 0.000000131\n",
      "train_loss: 0.085533, valid_loss: 0.066410\n",
      "train_f1: 0.884988, valid_f1: 0.914362\n",
      "--- 32.7010555267334 seconds ---\n",
      "Fold : 2\n",
      "Epoch : 0\n",
      "learning_rate: 0.000001000\n",
      "train_loss: 1.861045, valid_loss: 1.731913\n",
      "train_f1: 0.057297, valid_f1: 0.011472\n",
      "--- 32.893208742141724 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000011938\n",
      "train_loss: 1.753104, valid_loss: 1.554437\n",
      "train_f1: 0.063251, valid_f1: 0.133654\n",
      "--- 34.723302364349365 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000044274\n",
      "train_loss: 1.501805, valid_loss: 1.144241\n",
      "train_f1: 0.082097, valid_f1: 0.079099\n",
      "--- 35.326494455337524 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000096592\n",
      "train_loss: 1.111380, valid_loss: 0.746858\n",
      "train_f1: 0.107803, valid_f1: 0.097733\n",
      "--- 33.34448862075806 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000166599\n",
      "train_loss: 0.900274, valid_loss: 0.687394\n",
      "train_f1: 0.140194, valid_f1: 0.115742\n",
      "--- 32.60904121398926 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000251230\n",
      "train_loss: 0.806373, valid_loss: 0.649432\n",
      "train_f1: 0.157502, valid_f1: 0.174987\n",
      "--- 32.94791054725647 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000346779\n",
      "train_loss: 0.734282, valid_loss: 0.614467\n",
      "train_f1: 0.177049, valid_f1: 0.179114\n",
      "--- 33.22431921958923 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000449060\n",
      "train_loss: 0.685268, valid_loss: 0.587166\n",
      "train_f1: 0.193822, valid_f1: 0.191546\n",
      "--- 33.06038498878479 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000553594\n",
      "train_loss: 0.650202, valid_loss: 0.570232\n",
      "train_f1: 0.211484, valid_f1: 0.230846\n",
      "--- 33.2478551864624 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000655802\n",
      "train_loss: 0.622675, valid_loss: 0.544309\n",
      "train_f1: 0.228470, valid_f1: 0.245475\n",
      "--- 33.66129446029663 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000751209\n",
      "train_loss: 0.594565, valid_loss: 0.520610\n",
      "train_f1: 0.248359, valid_f1: 0.270241\n",
      "--- 33.0239531993866 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000835636\n",
      "train_loss: 0.561303, valid_loss: 0.472749\n",
      "train_f1: 0.283168, valid_f1: 0.330064\n",
      "--- 33.08206653594971 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000905384\n",
      "train_loss: 0.521123, valid_loss: 0.427214\n",
      "train_f1: 0.321912, valid_f1: 0.360237\n",
      "--- 33.318246841430664 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000957400\n",
      "train_loss: 0.478362, valid_loss: 0.398267\n",
      "train_f1: 0.357931, valid_f1: 0.370307\n",
      "--- 32.38023853302002 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000989405\n",
      "train_loss: 0.457948, valid_loss: 0.388198\n",
      "train_f1: 0.379836, valid_f1: 0.433309\n",
      "--- 32.58486294746399 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.001000000\n",
      "train_loss: 0.423483, valid_loss: 0.349768\n",
      "train_f1: 0.415477, valid_f1: 0.474791\n",
      "--- 32.85341668128967 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999860\n",
      "train_loss: 0.398599, valid_loss: 0.312250\n",
      "train_f1: 0.447747, valid_f1: 0.529458\n",
      "--- 32.799663066864014 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999450\n",
      "train_loss: 0.367040, valid_loss: 0.284091\n",
      "train_f1: 0.486614, valid_f1: 0.558955\n",
      "--- 34.15519428253174 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998769\n",
      "train_loss: 0.349984, valid_loss: 0.266390\n",
      "train_f1: 0.512692, valid_f1: 0.643588\n",
      "--- 33.591278076171875 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997818\n",
      "train_loss: 0.334279, valid_loss: 0.284663\n",
      "train_f1: 0.538243, valid_f1: 0.590500\n",
      "--- 33.31760239601135 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996598\n",
      "train_loss: 0.317934, valid_loss: 0.227834\n",
      "train_f1: 0.558519, valid_f1: 0.694142\n",
      "--- 34.58705925941467 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000995108\n",
      "train_loss: 0.297013, valid_loss: 0.214752\n",
      "train_f1: 0.582332, valid_f1: 0.725573\n",
      "--- 34.64132261276245 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993351\n",
      "train_loss: 0.290989, valid_loss: 0.211136\n",
      "train_f1: 0.599959, valid_f1: 0.721118\n",
      "--- 35.45128631591797 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991326\n",
      "train_loss: 0.277333, valid_loss: 0.194017\n",
      "train_f1: 0.609189, valid_f1: 0.738907\n",
      "--- 35.897945404052734 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000989035\n",
      "train_loss: 0.265495, valid_loss: 0.186620\n",
      "train_f1: 0.628761, valid_f1: 0.743213\n",
      "--- 35.89944911003113 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986480\n",
      "train_loss: 0.252907, valid_loss: 0.172695\n",
      "train_f1: 0.645254, valid_f1: 0.765367\n",
      "--- 35.44758224487305 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983661\n",
      "train_loss: 0.244536, valid_loss: 0.162716\n",
      "train_f1: 0.656583, valid_f1: 0.773939\n",
      "--- 35.582072257995605 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980580\n",
      "train_loss: 0.243152, valid_loss: 0.167027\n",
      "train_f1: 0.658875, valid_f1: 0.761294\n",
      "--- 35.14700794219971 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000977239\n",
      "train_loss: 0.226424, valid_loss: 0.148040\n",
      "train_f1: 0.677218, valid_f1: 0.784354\n",
      "--- 35.90730047225952 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973639\n",
      "train_loss: 0.217233, valid_loss: 0.147735\n",
      "train_f1: 0.687179, valid_f1: 0.782707\n",
      "--- 35.35762095451355 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969783\n",
      "train_loss: 0.211849, valid_loss: 0.132979\n",
      "train_f1: 0.692451, valid_f1: 0.792132\n",
      "--- 35.293176889419556 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965673\n",
      "train_loss: 0.208236, valid_loss: 0.145242\n",
      "train_f1: 0.699228, valid_f1: 0.772603\n",
      "--- 35.37604355812073 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000961310\n",
      "train_loss: 0.202082, valid_loss: 0.134558\n",
      "train_f1: 0.707612, valid_f1: 0.782238\n",
      "--- 34.509522676467896 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956698\n",
      "train_loss: 0.190898, valid_loss: 0.122675\n",
      "train_f1: 0.717125, valid_f1: 0.791304\n",
      "--- 35.68747115135193 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951838\n",
      "train_loss: 0.187922, valid_loss: 0.120274\n",
      "train_f1: 0.721459, valid_f1: 0.803201\n",
      "--- 35.61650514602661 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946733\n",
      "train_loss: 0.188036, valid_loss: 0.121406\n",
      "train_f1: 0.722576, valid_f1: 0.799168\n",
      "--- 35.56519794464111 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000941387\n",
      "train_loss: 0.174042, valid_loss: 0.110374\n",
      "train_f1: 0.733711, valid_f1: 0.808199\n",
      "--- 35.88839244842529 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935802\n",
      "train_loss: 0.167603, valid_loss: 0.109622\n",
      "train_f1: 0.740851, valid_f1: 0.805338\n",
      "--- 35.17133593559265 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929980\n",
      "train_loss: 0.164525, valid_loss: 0.108225\n",
      "train_f1: 0.747227, valid_f1: 0.804542\n",
      "--- 34.419609785079956 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923926\n",
      "train_loss: 0.158536, valid_loss: 0.103949\n",
      "train_f1: 0.751314, valid_f1: 0.810611\n",
      "--- 35.382246017456055 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917642\n",
      "train_loss: 0.154015, valid_loss: 0.103020\n",
      "train_f1: 0.756599, valid_f1: 0.801400\n",
      "--- 35.14061903953552 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000911132\n",
      "train_loss: 0.153817, valid_loss: 0.099546\n",
      "train_f1: 0.756065, valid_f1: 0.805047\n",
      "--- 35.317890644073486 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000904400\n",
      "train_loss: 0.146507, valid_loss: 0.095596\n",
      "train_f1: 0.763505, valid_f1: 0.815148\n",
      "--- 35.13065767288208 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000897448\n",
      "train_loss: 0.150395, valid_loss: 0.096284\n",
      "train_f1: 0.763339, valid_f1: 0.815405\n",
      "--- 35.45475459098816 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000890282\n",
      "train_loss: 0.145210, valid_loss: 0.096943\n",
      "train_f1: 0.767772, valid_f1: 0.809146\n",
      "--- 35.32484269142151 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882903\n",
      "train_loss: 0.149057, valid_loss: 0.113288\n",
      "train_f1: 0.768498, valid_f1: 0.801257\n",
      "--- 35.83135676383972 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000875318\n",
      "train_loss: 0.145849, valid_loss: 0.092787\n",
      "train_f1: 0.766840, valid_f1: 0.816454\n",
      "--- 35.68174076080322 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000867529\n",
      "train_loss: 0.138833, valid_loss: 0.089814\n",
      "train_f1: 0.776550, valid_f1: 0.818406\n",
      "--- 35.27027177810669 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000859542\n",
      "train_loss: 0.136327, valid_loss: 0.093240\n",
      "train_f1: 0.781027, valid_f1: 0.812836\n",
      "--- 35.22563147544861 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000851359\n",
      "train_loss: 0.135496, valid_loss: 0.086644\n",
      "train_f1: 0.784300, valid_f1: 0.821712\n",
      "--- 36.07820248603821 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842986\n",
      "train_loss: 0.132246, valid_loss: 0.087936\n",
      "train_f1: 0.787686, valid_f1: 0.819507\n",
      "--- 36.043410539627075 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000834428\n",
      "train_loss: 0.130874, valid_loss: 0.106269\n",
      "train_f1: 0.789973, valid_f1: 0.805115\n",
      "--- 36.06018400192261 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000825689\n",
      "train_loss: 0.131977, valid_loss: 0.093587\n",
      "train_f1: 0.793791, valid_f1: 0.809281\n",
      "--- 36.228333473205566 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816773\n",
      "train_loss: 0.127602, valid_loss: 0.084258\n",
      "train_f1: 0.799010, valid_f1: 0.823446\n",
      "--- 36.29294562339783 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000807685\n",
      "train_loss: 0.125331, valid_loss: 0.083299\n",
      "train_f1: 0.803068, valid_f1: 0.822597\n",
      "--- 35.40131616592407 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000798431\n",
      "train_loss: 0.125251, valid_loss: 0.082866\n",
      "train_f1: 0.802820, valid_f1: 0.824044\n",
      "--- 37.31447410583496 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000789015\n",
      "train_loss: 0.122358, valid_loss: 0.086682\n",
      "train_f1: 0.809147, valid_f1: 0.818484\n",
      "--- 36.40464925765991 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000779443\n",
      "train_loss: 0.123088, valid_loss: 0.084195\n",
      "train_f1: 0.810200, valid_f1: 0.867266\n",
      "--- 35.888742446899414 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000769720\n",
      "train_loss: 0.119507, valid_loss: 0.083919\n",
      "train_f1: 0.815968, valid_f1: 0.825345\n",
      "--- 35.84100651741028 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759850\n",
      "train_loss: 0.118468, valid_loss: 0.083592\n",
      "train_f1: 0.819528, valid_f1: 0.850253\n",
      "--- 36.17781925201416 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000749840\n",
      "train_loss: 0.117051, valid_loss: 0.080299\n",
      "train_f1: 0.821924, valid_f1: 0.829638\n",
      "--- 35.93009424209595 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000739695\n",
      "train_loss: 0.117028, valid_loss: 0.079518\n",
      "train_f1: 0.824191, valid_f1: 0.880399\n",
      "--- 36.57403922080994 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000729419\n",
      "train_loss: 0.114196, valid_loss: 0.078724\n",
      "train_f1: 0.828031, valid_f1: 0.875857\n",
      "--- 35.47331881523132 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000719020\n",
      "train_loss: 0.114753, valid_loss: 0.078687\n",
      "train_f1: 0.829396, valid_f1: 0.888631\n",
      "--- 36.23120045661926 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000708501\n",
      "train_loss: 0.115398, valid_loss: 0.080384\n",
      "train_f1: 0.830353, valid_f1: 0.896096\n",
      "--- 36.36281871795654 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000697870\n",
      "train_loss: 0.112970, valid_loss: 0.079332\n",
      "train_f1: 0.833760, valid_f1: 0.894585\n",
      "--- 35.520962715148926 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000687132\n",
      "train_loss: 0.113080, valid_loss: 0.078596\n",
      "train_f1: 0.835181, valid_f1: 0.901166\n",
      "--- 35.4766366481781 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000676292\n",
      "train_loss: 0.111149, valid_loss: 0.076818\n",
      "train_f1: 0.838864, valid_f1: 0.904338\n",
      "--- 36.336610317230225 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000665357\n",
      "train_loss: 0.110820, valid_loss: 0.083446\n",
      "train_f1: 0.839434, valid_f1: 0.887875\n",
      "--- 35.72062849998474 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000654333\n",
      "train_loss: 0.110545, valid_loss: 0.077288\n",
      "train_f1: 0.841210, valid_f1: 0.899973\n",
      "--- 36.195369243621826 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000643225\n",
      "train_loss: 0.108569, valid_loss: 0.078356\n",
      "train_f1: 0.843550, valid_f1: 0.903130\n",
      "--- 36.184900760650635 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000632039\n",
      "train_loss: 0.107160, valid_loss: 0.084994\n",
      "train_f1: 0.846737, valid_f1: 0.886133\n",
      "--- 35.9045774936676 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000620782\n",
      "train_loss: 0.107795, valid_loss: 0.076009\n",
      "train_f1: 0.847059, valid_f1: 0.906276\n",
      "--- 36.361085653305054 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000609459\n",
      "train_loss: 0.133550, valid_loss: 0.078710\n",
      "train_f1: 0.825617, valid_f1: 0.906053\n",
      "--- 35.73780584335327 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000598077\n",
      "train_loss: 0.110125, valid_loss: 0.075197\n",
      "train_f1: 0.846297, valid_f1: 0.905577\n",
      "--- 36.243043661117554 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000586642\n",
      "train_loss: 0.107366, valid_loss: 0.074707\n",
      "train_f1: 0.848320, valid_f1: 0.908085\n",
      "--- 36.514026165008545 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000575160\n",
      "train_loss: 0.106141, valid_loss: 0.073059\n",
      "train_f1: 0.850148, valid_f1: 0.910031\n",
      "--- 36.1115026473999 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000563638\n",
      "train_loss: 0.104548, valid_loss: 0.072646\n",
      "train_f1: 0.852775, valid_f1: 0.908350\n",
      "--- 35.74704074859619 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000552081\n",
      "train_loss: 0.103535, valid_loss: 0.075260\n",
      "train_f1: 0.853488, valid_f1: 0.905256\n",
      "--- 35.63642406463623 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000540495\n",
      "train_loss: 0.102830, valid_loss: 0.071957\n",
      "train_f1: 0.855588, valid_f1: 0.910792\n",
      "--- 34.95302772521973 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000528888\n",
      "train_loss: 0.102643, valid_loss: 0.072705\n",
      "train_f1: 0.855528, valid_f1: 0.909277\n",
      "--- 35.10677146911621 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000517265\n",
      "train_loss: 0.102413, valid_loss: 0.072081\n",
      "train_f1: 0.857623, valid_f1: 0.910692\n",
      "--- 35.533326864242554 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000505633\n",
      "train_loss: 0.101681, valid_loss: 0.071537\n",
      "train_f1: 0.858460, valid_f1: 0.911596\n",
      "--- 36.242018938064575 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493998\n",
      "train_loss: 0.100748, valid_loss: 0.072019\n",
      "train_f1: 0.860261, valid_f1: 0.910245\n",
      "--- 36.030168533325195 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000482366\n",
      "train_loss: 0.101402, valid_loss: 0.071579\n",
      "train_f1: 0.860125, valid_f1: 0.911407\n",
      "--- 36.05375623703003 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000470743\n",
      "train_loss: 0.102992, valid_loss: 0.072241\n",
      "train_f1: 0.860020, valid_f1: 0.910581\n",
      "--- 35.7806282043457 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000459137\n",
      "train_loss: 0.100465, valid_loss: 0.071758\n",
      "train_f1: 0.861013, valid_f1: 0.907327\n",
      "--- 36.440937995910645 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000447552\n",
      "train_loss: 0.098789, valid_loss: 0.072872\n",
      "train_f1: 0.862743, valid_f1: 0.907773\n",
      "--- 35.725062131881714 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435996\n",
      "train_loss: 0.098189, valid_loss: 0.070504\n",
      "train_f1: 0.864184, valid_f1: 0.912499\n",
      "--- 35.251211166381836 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000424475\n",
      "train_loss: 0.098413, valid_loss: 0.072583\n",
      "train_f1: 0.863964, valid_f1: 0.908020\n",
      "--- 36.13337707519531 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412994\n",
      "train_loss: 0.097208, valid_loss: 0.070728\n",
      "train_f1: 0.865428, valid_f1: 0.912154\n",
      "--- 35.91598176956177 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000401561\n",
      "train_loss: 0.097267, valid_loss: 0.069750\n",
      "train_f1: 0.866096, valid_f1: 0.911978\n",
      "--- 35.71886157989502 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000390181\n",
      "train_loss: 0.096720, valid_loss: 0.071736\n",
      "train_f1: 0.866889, valid_f1: 0.907595\n",
      "--- 36.14060831069946 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000378860\n",
      "train_loss: 0.096373, valid_loss: 0.069868\n",
      "train_f1: 0.867867, valid_f1: 0.913333\n",
      "--- 35.30331492424011 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000367605\n",
      "train_loss: 0.095877, valid_loss: 0.069452\n",
      "train_f1: 0.869262, valid_f1: 0.913069\n",
      "--- 35.54446244239807 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000356422\n",
      "train_loss: 0.095941, valid_loss: 0.069357\n",
      "train_f1: 0.870185, valid_f1: 0.913757\n",
      "--- 36.099828243255615 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000345316\n",
      "train_loss: 0.094558, valid_loss: 0.069302\n",
      "train_f1: 0.870513, valid_f1: 0.913859\n",
      "--- 35.405702114105225 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000334294\n",
      "train_loss: 0.095273, valid_loss: 0.069636\n",
      "train_f1: 0.870827, valid_f1: 0.912819\n",
      "--- 35.23893737792969 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000323362\n",
      "train_loss: 0.094683, valid_loss: 0.070697\n",
      "train_f1: 0.870216, valid_f1: 0.910857\n",
      "--- 35.27875900268555 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000312526\n",
      "train_loss: 0.093933, valid_loss: 0.068449\n",
      "train_f1: 0.871488, valid_f1: 0.914997\n",
      "--- 35.397037982940674 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000301791\n",
      "train_loss: 0.093945, valid_loss: 0.070037\n",
      "train_f1: 0.872222, valid_f1: 0.913006\n",
      "--- 35.78288435935974 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000291163\n",
      "train_loss: 0.095390, valid_loss: 0.078659\n",
      "train_f1: 0.872297, valid_f1: 0.909880\n",
      "--- 35.077144622802734 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000280649\n",
      "train_loss: 0.094499, valid_loss: 0.068723\n",
      "train_f1: 0.873300, valid_f1: 0.913224\n",
      "--- 36.32594561576843 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000270253\n",
      "train_loss: 0.093634, valid_loss: 0.067643\n",
      "train_f1: 0.873874, valid_f1: 0.914821\n",
      "--- 36.20093631744385 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259981\n",
      "train_loss: 0.093235, valid_loss: 0.067814\n",
      "train_f1: 0.873758, valid_f1: 0.914482\n",
      "--- 34.89057779312134 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000249840\n",
      "train_loss: 0.092295, valid_loss: 0.067353\n",
      "train_f1: 0.875490, valid_f1: 0.915170\n",
      "--- 35.05782866477966 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239834\n",
      "train_loss: 0.091681, valid_loss: 0.068206\n",
      "train_f1: 0.876196, valid_f1: 0.914993\n",
      "--- 35.61589765548706 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229969\n",
      "train_loss: 0.092534, valid_loss: 0.067482\n",
      "train_f1: 0.875434, valid_f1: 0.915130\n",
      "--- 35.35425591468811 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.000220251\n",
      "train_loss: 0.090925, valid_loss: 0.067497\n",
      "train_f1: 0.876854, valid_f1: 0.915182\n",
      "--- 34.67783045768738 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.000210683\n",
      "train_loss: 0.091407, valid_loss: 0.067165\n",
      "train_f1: 0.876562, valid_f1: 0.916422\n",
      "--- 35.93717861175537 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.000201273\n",
      "train_loss: 0.090968, valid_loss: 0.067165\n",
      "train_f1: 0.877512, valid_f1: 0.915570\n",
      "--- 34.7368438243866 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.000192024\n",
      "train_loss: 0.091116, valid_loss: 0.067208\n",
      "train_f1: 0.877522, valid_f1: 0.915616\n",
      "--- 35.26376461982727 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.000182942\n",
      "train_loss: 0.091182, valid_loss: 0.066803\n",
      "train_f1: 0.876920, valid_f1: 0.916367\n",
      "--- 35.752519369125366 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.000174031\n",
      "train_loss: 0.090196, valid_loss: 0.066840\n",
      "train_f1: 0.878976, valid_f1: 0.916566\n",
      "--- 35.27870154380798 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.000165298\n",
      "train_loss: 0.089812, valid_loss: 0.066280\n",
      "train_f1: 0.878750, valid_f1: 0.916396\n",
      "--- 36.192591190338135 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.000156745\n",
      "train_loss: 0.089208, valid_loss: 0.066345\n",
      "train_f1: 0.879392, valid_f1: 0.916402\n",
      "--- 35.30182671546936 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.000148378\n",
      "train_loss: 0.090214, valid_loss: 0.066915\n",
      "train_f1: 0.877818, valid_f1: 0.916552\n",
      "--- 35.34002923965454 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.000140202\n",
      "train_loss: 0.089281, valid_loss: 0.066496\n",
      "train_f1: 0.879630, valid_f1: 0.916671\n",
      "--- 35.70258069038391 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.000132220\n",
      "train_loss: 0.089120, valid_loss: 0.066406\n",
      "train_f1: 0.879811, valid_f1: 0.917013\n",
      "--- 35.72646450996399 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.000124438\n",
      "train_loss: 0.089318, valid_loss: 0.066782\n",
      "train_f1: 0.879938, valid_f1: 0.916188\n",
      "--- 35.242865800857544 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.000116859\n",
      "train_loss: 0.089647, valid_loss: 0.067731\n",
      "train_f1: 0.880375, valid_f1: 0.914940\n",
      "--- 35.555487394332886 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.000109488\n",
      "train_loss: 0.089564, valid_loss: 0.066232\n",
      "train_f1: 0.879906, valid_f1: 0.917339\n",
      "--- 35.52029728889465 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.000102328\n",
      "train_loss: 0.089293, valid_loss: 0.066241\n",
      "train_f1: 0.881226, valid_f1: 0.916747\n",
      "--- 35.732048749923706 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000095383\n",
      "train_loss: 0.088772, valid_loss: 0.065973\n",
      "train_f1: 0.881480, valid_f1: 0.917642\n",
      "--- 35.5424017906189 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000088658\n",
      "train_loss: 0.087957, valid_loss: 0.065917\n",
      "train_f1: 0.881372, valid_f1: 0.916739\n",
      "--- 35.312487840652466 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000082155\n",
      "train_loss: 0.088433, valid_loss: 0.066196\n",
      "train_f1: 0.881527, valid_f1: 0.917047\n",
      "--- 35.794397830963135 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000075878\n",
      "train_loss: 0.088118, valid_loss: 0.065827\n",
      "train_f1: 0.881412, valid_f1: 0.917448\n",
      "--- 35.35262751579285 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000069831\n",
      "train_loss: 0.088360, valid_loss: 0.066417\n",
      "train_f1: 0.881695, valid_f1: 0.915353\n",
      "--- 35.66751456260681 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000064017\n",
      "train_loss: 0.088264, valid_loss: 0.065728\n",
      "train_f1: 0.881647, valid_f1: 0.917387\n",
      "--- 35.16619348526001 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000058440\n",
      "train_loss: 0.087984, valid_loss: 0.065915\n",
      "train_f1: 0.882581, valid_f1: 0.916404\n",
      "--- 36.345399141311646 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000053101\n",
      "train_loss: 0.088298, valid_loss: 0.065655\n",
      "train_f1: 0.882118, valid_f1: 0.917338\n",
      "--- 35.16887879371643 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000048004\n",
      "train_loss: 0.087877, valid_loss: 0.065552\n",
      "train_f1: 0.882786, valid_f1: 0.917214\n",
      "--- 35.61859083175659 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000043152\n",
      "train_loss: 0.087880, valid_loss: 0.065640\n",
      "train_f1: 0.882697, valid_f1: 0.916972\n",
      "--- 35.4277241230011 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000038548\n",
      "train_loss: 0.087451, valid_loss: 0.065585\n",
      "train_f1: 0.882593, valid_f1: 0.917109\n",
      "--- 35.2025089263916 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000034193\n",
      "train_loss: 0.087533, valid_loss: 0.065776\n",
      "train_f1: 0.882788, valid_f1: 0.916178\n",
      "--- 35.79080867767334 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000030091\n",
      "train_loss: 0.087264, valid_loss: 0.065391\n",
      "train_f1: 0.882731, valid_f1: 0.917413\n",
      "--- 35.7007999420166 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000026243\n",
      "train_loss: 0.087220, valid_loss: 0.065400\n",
      "train_f1: 0.883054, valid_f1: 0.917465\n",
      "--- 35.66436576843262 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000022651\n",
      "train_loss: 0.086894, valid_loss: 0.065432\n",
      "train_f1: 0.883483, valid_f1: 0.917211\n",
      "--- 35.303717374801636 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000019318\n",
      "train_loss: 0.087652, valid_loss: 0.065519\n",
      "train_f1: 0.882945, valid_f1: 0.916954\n",
      "--- 35.57433867454529 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000016246\n",
      "train_loss: 0.087225, valid_loss: 0.065343\n",
      "train_f1: 0.883879, valid_f1: 0.917394\n",
      "--- 35.95202875137329 seconds ---\n",
      "Epoch : 140\n",
      "learning_rate: 0.000013435\n",
      "train_loss: 0.087018, valid_loss: 0.065379\n",
      "train_f1: 0.883098, valid_f1: 0.917327\n",
      "--- 35.645955324172974 seconds ---\n",
      "Epoch : 141\n",
      "learning_rate: 0.000010888\n",
      "train_loss: 0.087055, valid_loss: 0.065546\n",
      "train_f1: 0.883360, valid_f1: 0.916791\n",
      "--- 35.83841276168823 seconds ---\n",
      "Epoch : 142\n",
      "learning_rate: 0.000008606\n",
      "train_loss: 0.086899, valid_loss: 0.065353\n",
      "train_f1: 0.883536, valid_f1: 0.917373\n",
      "--- 35.52021265029907 seconds ---\n",
      "Epoch : 143\n",
      "learning_rate: 0.000006589\n",
      "train_loss: 0.086845, valid_loss: 0.065346\n",
      "train_f1: 0.883254, valid_f1: 0.917372\n",
      "Early Stopping...\n",
      "Best Val Score: 0.917642\n",
      "Fold : 3\n",
      "Epoch : 0\n",
      "learning_rate: 0.000001000\n",
      "train_loss: 2.310418, valid_loss: 1.954250\n",
      "train_f1: 0.059524, valid_f1: 0.044463\n",
      "--- 35.75454235076904 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000011938\n",
      "train_loss: 2.115463, valid_loss: 1.703377\n",
      "train_f1: 0.062255, valid_f1: 0.026135\n",
      "--- 35.86790990829468 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000044274\n",
      "train_loss: 1.744891, valid_loss: 1.252494\n",
      "train_f1: 0.068680, valid_f1: 0.052193\n",
      "--- 35.87277317047119 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000096592\n",
      "train_loss: 1.327329, valid_loss: 0.864917\n",
      "train_f1: 0.084984, valid_f1: 0.082115\n",
      "--- 35.522485971450806 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000166599\n",
      "train_loss: 1.033361, valid_loss: 0.734943\n",
      "train_f1: 0.109712, valid_f1: 0.091309\n",
      "--- 35.638675928115845 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000251230\n",
      "train_loss: 0.875136, valid_loss: 0.681788\n",
      "train_f1: 0.131852, valid_f1: 0.111071\n",
      "--- 34.153573513031006 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000346779\n",
      "train_loss: 0.778301, valid_loss: 0.644657\n",
      "train_f1: 0.151390, valid_f1: 0.151686\n",
      "--- 35.25139546394348 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000449060\n",
      "train_loss: 0.714734, valid_loss: 0.602504\n",
      "train_f1: 0.169197, valid_f1: 0.154846\n",
      "--- 35.684792041778564 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000553594\n",
      "train_loss: 0.675673, valid_loss: 0.587218\n",
      "train_f1: 0.185641, valid_f1: 0.184936\n",
      "--- 35.02015447616577 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000655802\n",
      "train_loss: 0.643582, valid_loss: 0.567372\n",
      "train_f1: 0.207256, valid_f1: 0.226141\n",
      "--- 35.56470251083374 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000751209\n",
      "train_loss: 0.617984, valid_loss: 0.555191\n",
      "train_f1: 0.226248, valid_f1: 0.218095\n",
      "--- 35.17347240447998 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000835636\n",
      "train_loss: 0.599379, valid_loss: 0.532594\n",
      "train_f1: 0.239178, valid_f1: 0.278151\n",
      "--- 35.11333203315735 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000905384\n",
      "train_loss: 0.569050, valid_loss: 0.512010\n",
      "train_f1: 0.263369, valid_f1: 0.315089\n",
      "--- 35.30102467536926 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000957400\n",
      "train_loss: 0.533380, valid_loss: 0.452769\n",
      "train_f1: 0.290726, valid_f1: 0.347249\n",
      "--- 35.23152828216553 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000989405\n",
      "train_loss: 0.514398, valid_loss: 0.438426\n",
      "train_f1: 0.311287, valid_f1: 0.352135\n",
      "--- 35.45768356323242 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.001000000\n",
      "train_loss: 0.476989, valid_loss: 0.423544\n",
      "train_f1: 0.343385, valid_f1: 0.345585\n",
      "--- 35.908408880233765 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999860\n",
      "train_loss: 0.455848, valid_loss: 0.385824\n",
      "train_f1: 0.370096, valid_f1: 0.428035\n",
      "--- 35.49433183670044 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999450\n",
      "train_loss: 0.434619, valid_loss: 0.356385\n",
      "train_f1: 0.401066, valid_f1: 0.455339\n",
      "--- 35.83376359939575 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998769\n",
      "train_loss: 0.412276, valid_loss: 0.333055\n",
      "train_f1: 0.429204, valid_f1: 0.549748\n",
      "--- 35.30472254753113 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997818\n",
      "train_loss: 0.399868, valid_loss: 0.565654\n",
      "train_f1: 0.461170, valid_f1: 0.501938\n",
      "--- 34.82508873939514 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996598\n",
      "train_loss: 0.459878, valid_loss: 0.319525\n",
      "train_f1: 0.437748, valid_f1: 0.598667\n",
      "--- 34.28505611419678 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000995108\n",
      "train_loss: 0.379689, valid_loss: 0.286085\n",
      "train_f1: 0.494201, valid_f1: 0.630221\n",
      "--- 35.918495178222656 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993351\n",
      "train_loss: 0.353717, valid_loss: 0.262733\n",
      "train_f1: 0.517504, valid_f1: 0.670417\n",
      "--- 36.0421621799469 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991326\n",
      "train_loss: 0.327883, valid_loss: 0.248233\n",
      "train_f1: 0.548909, valid_f1: 0.679137\n",
      "--- 35.57816004753113 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000989035\n",
      "train_loss: 0.314727, valid_loss: 0.230533\n",
      "train_f1: 0.561773, valid_f1: 0.686044\n",
      "--- 35.669082164764404 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986480\n",
      "train_loss: 0.293332, valid_loss: 0.211510\n",
      "train_f1: 0.584649, valid_f1: 0.725239\n",
      "--- 35.608856439590454 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983661\n",
      "train_loss: 0.279043, valid_loss: 0.207892\n",
      "train_f1: 0.603782, valid_f1: 0.717089\n",
      "--- 35.14725112915039 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980580\n",
      "train_loss: 0.265657, valid_loss: 0.193695\n",
      "train_f1: 0.620235, valid_f1: 0.724707\n",
      "--- 35.769144773483276 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000977239\n",
      "train_loss: 0.259636, valid_loss: 0.186542\n",
      "train_f1: 0.630121, valid_f1: 0.745744\n",
      "--- 35.28967046737671 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973639\n",
      "train_loss: 0.249012, valid_loss: 0.183507\n",
      "train_f1: 0.641770, valid_f1: 0.732356\n",
      "--- 34.73274874687195 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969783\n",
      "train_loss: 0.237030, valid_loss: 0.171660\n",
      "train_f1: 0.658313, valid_f1: 0.750067\n",
      "--- 35.26784300804138 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965673\n",
      "train_loss: 0.235604, valid_loss: 0.163546\n",
      "train_f1: 0.661334, valid_f1: 0.770665\n",
      "--- 35.73590016365051 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000961310\n",
      "train_loss: 0.222777, valid_loss: 0.167144\n",
      "train_f1: 0.674957, valid_f1: 0.734644\n",
      "--- 35.34493136405945 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956698\n",
      "train_loss: 0.214923, valid_loss: 0.150885\n",
      "train_f1: 0.686220, valid_f1: 0.778083\n",
      "--- 34.742353200912476 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951838\n",
      "train_loss: 0.204404, valid_loss: 0.147220\n",
      "train_f1: 0.698947, valid_f1: 0.779917\n",
      "--- 35.57859659194946 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946733\n",
      "train_loss: 0.200034, valid_loss: 0.147140\n",
      "train_f1: 0.702968, valid_f1: 0.754369\n",
      "--- 35.782904386520386 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000941387\n",
      "train_loss: 0.194776, valid_loss: 0.140790\n",
      "train_f1: 0.711701, valid_f1: 0.780814\n",
      "--- 35.45836353302002 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935802\n",
      "train_loss: 0.184906, valid_loss: 0.135210\n",
      "train_f1: 0.721759, valid_f1: 0.786257\n",
      "--- 35.56594634056091 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929980\n",
      "train_loss: 0.177557, valid_loss: 0.131711\n",
      "train_f1: 0.728931, valid_f1: 0.784167\n",
      "--- 35.215081214904785 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923926\n",
      "train_loss: 0.175927, valid_loss: 0.132066\n",
      "train_f1: 0.730872, valid_f1: 0.781372\n",
      "--- 35.12581825256348 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917642\n",
      "train_loss: 0.191189, valid_loss: 0.186726\n",
      "train_f1: 0.724100, valid_f1: 0.742395\n",
      "--- 35.26740074157715 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000911132\n",
      "train_loss: 0.224347, valid_loss: 0.134776\n",
      "train_f1: 0.691302, valid_f1: 0.782605\n",
      "--- 34.656198501586914 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000904400\n",
      "train_loss: 0.207547, valid_loss: 0.128400\n",
      "train_f1: 0.714988, valid_f1: 0.790765\n",
      "--- 35.603538513183594 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000897448\n",
      "train_loss: 0.167009, valid_loss: 0.117896\n",
      "train_f1: 0.744992, valid_f1: 0.797559\n",
      "--- 35.94471526145935 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000890282\n",
      "train_loss: 0.159421, valid_loss: 0.126472\n",
      "train_f1: 0.751152, valid_f1: 0.794019\n",
      "--- 35.80101656913757 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882903\n",
      "train_loss: 0.155692, valid_loss: 0.113572\n",
      "train_f1: 0.757275, valid_f1: 0.800466\n",
      "--- 35.31139063835144 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000875318\n",
      "train_loss: 0.153334, valid_loss: 0.117778\n",
      "train_f1: 0.760086, valid_f1: 0.791791\n",
      "--- 35.05858755111694 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000867529\n",
      "train_loss: 0.149981, valid_loss: 0.117854\n",
      "train_f1: 0.762593, valid_f1: 0.800344\n",
      "--- 34.79932880401611 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000859542\n",
      "train_loss: 0.146350, valid_loss: 0.115647\n",
      "train_f1: 0.767109, valid_f1: 0.802653\n",
      "--- 35.63099408149719 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000851359\n",
      "train_loss: 0.142575, valid_loss: 0.115911\n",
      "train_f1: 0.770138, valid_f1: 0.796013\n",
      "--- 35.61347508430481 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842986\n",
      "train_loss: 0.141530, valid_loss: 0.115532\n",
      "train_f1: 0.775277, valid_f1: 0.801796\n",
      "--- 35.46418285369873 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000834428\n",
      "train_loss: 0.143911, valid_loss: 0.112643\n",
      "train_f1: 0.775702, valid_f1: 0.806108\n",
      "--- 35.158430337905884 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000825689\n",
      "train_loss: 0.135441, valid_loss: 0.104971\n",
      "train_f1: 0.782420, valid_f1: 0.808359\n",
      "--- 35.41132593154907 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816773\n",
      "train_loss: 0.134962, valid_loss: 0.110889\n",
      "train_f1: 0.785394, valid_f1: 0.804145\n",
      "--- 35.36225438117981 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000807685\n",
      "train_loss: 0.133019, valid_loss: 0.117826\n",
      "train_f1: 0.788543, valid_f1: 0.805265\n",
      "--- 35.40345072746277 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000798431\n",
      "train_loss: 0.138531, valid_loss: 0.147658\n",
      "train_f1: 0.784089, valid_f1: 0.771758\n",
      "--- 35.41112208366394 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000789015\n",
      "train_loss: 0.161351, valid_loss: 0.104220\n",
      "train_f1: 0.767339, valid_f1: 0.806151\n",
      "--- 35.0674307346344 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000779443\n",
      "train_loss: 0.133124, valid_loss: 0.107968\n",
      "train_f1: 0.792918, valid_f1: 0.808187\n",
      "--- 35.88769340515137 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000769720\n",
      "train_loss: 0.128103, valid_loss: 0.103550\n",
      "train_f1: 0.798514, valid_f1: 0.811438\n",
      "--- 35.40004229545593 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759850\n",
      "train_loss: 0.125574, valid_loss: 0.105587\n",
      "train_f1: 0.802711, valid_f1: 0.811482\n",
      "--- 34.46227765083313 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000749840\n",
      "train_loss: 0.125467, valid_loss: 0.103443\n",
      "train_f1: 0.805397, valid_f1: 0.805436\n",
      "--- 35.39667797088623 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000739695\n",
      "train_loss: 0.124022, valid_loss: 0.106022\n",
      "train_f1: 0.807994, valid_f1: 0.809500\n",
      "--- 35.449374198913574 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000729419\n",
      "train_loss: 0.122123, valid_loss: 0.107244\n",
      "train_f1: 0.812927, valid_f1: 0.812908\n",
      "--- 34.865782022476196 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000719020\n",
      "train_loss: 0.120537, valid_loss: 0.112120\n",
      "train_f1: 0.815331, valid_f1: 0.803229\n",
      "--- 34.6920428276062 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000708501\n",
      "train_loss: 0.120419, valid_loss: 0.095463\n",
      "train_f1: 0.817792, valid_f1: 0.814535\n",
      "--- 35.28670382499695 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000697870\n",
      "train_loss: 0.118471, valid_loss: 0.105727\n",
      "train_f1: 0.821800, valid_f1: 0.813306\n",
      "--- 35.24114108085632 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000687132\n",
      "train_loss: 0.117923, valid_loss: 0.098087\n",
      "train_f1: 0.821658, valid_f1: 0.813491\n",
      "--- 35.49651527404785 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000676292\n",
      "train_loss: 0.123958, valid_loss: 0.118519\n",
      "train_f1: 0.822083, valid_f1: 0.795817\n",
      "--- 35.09867739677429 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000665357\n",
      "train_loss: 0.118375, valid_loss: 0.091850\n",
      "train_f1: 0.826424, valid_f1: 0.816674\n",
      "--- 35.45310115814209 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000654333\n",
      "train_loss: 0.115559, valid_loss: 0.097749\n",
      "train_f1: 0.830367, valid_f1: 0.858606\n",
      "--- 35.08164691925049 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000643225\n",
      "train_loss: 0.114807, valid_loss: 0.103272\n",
      "train_f1: 0.831681, valid_f1: 0.854668\n",
      "--- 35.429502964019775 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000632039\n",
      "train_loss: 0.111536, valid_loss: 0.101190\n",
      "train_f1: 0.836684, valid_f1: 0.869783\n",
      "--- 35.47314715385437 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000620782\n",
      "train_loss: 0.111060, valid_loss: 0.105070\n",
      "train_f1: 0.837659, valid_f1: 0.822168\n",
      "--- 35.36424541473389 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000609459\n",
      "train_loss: 0.110866, valid_loss: 0.103857\n",
      "train_f1: 0.839896, valid_f1: 0.877322\n",
      "--- 35.41865682601929 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000598077\n",
      "train_loss: 0.110440, valid_loss: 0.094803\n",
      "train_f1: 0.841093, valid_f1: 0.878557\n",
      "--- 35.02070689201355 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000586642\n",
      "train_loss: 0.109984, valid_loss: 0.110035\n",
      "train_f1: 0.841291, valid_f1: 0.875895\n",
      "--- 35.74259114265442 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000575160\n",
      "train_loss: 0.109037, valid_loss: 0.093930\n",
      "train_f1: 0.842890, valid_f1: 0.878826\n",
      "--- 35.264636516571045 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000563638\n",
      "train_loss: 0.107503, valid_loss: 0.096101\n",
      "train_f1: 0.846875, valid_f1: 0.879878\n",
      "--- 35.31390070915222 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000552081\n",
      "train_loss: 0.106679, valid_loss: 0.100169\n",
      "train_f1: 0.847888, valid_f1: 0.881655\n",
      "--- 35.263564109802246 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000540495\n",
      "train_loss: 0.110627, valid_loss: 0.092213\n",
      "train_f1: 0.848953, valid_f1: 0.890017\n",
      "--- 34.83633804321289 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000528888\n",
      "train_loss: 0.106196, valid_loss: 0.110595\n",
      "train_f1: 0.850053, valid_f1: 0.891857\n",
      "--- 35.17906332015991 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000517265\n",
      "train_loss: 0.104993, valid_loss: 0.105601\n",
      "train_f1: 0.852263, valid_f1: 0.889734\n",
      "--- 35.93731164932251 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000505633\n",
      "train_loss: 0.104359, valid_loss: 0.103397\n",
      "train_f1: 0.853982, valid_f1: 0.893208\n",
      "--- 35.287089347839355 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493998\n",
      "train_loss: 0.103668, valid_loss: 0.096643\n",
      "train_f1: 0.855040, valid_f1: 0.886887\n",
      "--- 35.17899179458618 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000482366\n",
      "train_loss: 0.103214, valid_loss: 0.089144\n",
      "train_f1: 0.855705, valid_f1: 0.895818\n",
      "--- 35.08752942085266 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000470743\n",
      "train_loss: 0.102779, valid_loss: 0.104881\n",
      "train_f1: 0.856843, valid_f1: 0.894972\n",
      "--- 35.198728799819946 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000459137\n",
      "train_loss: 0.102478, valid_loss: 0.104649\n",
      "train_f1: 0.857411, valid_f1: 0.895714\n",
      "--- 35.3513970375061 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000447552\n",
      "train_loss: 0.103118, valid_loss: 0.106234\n",
      "train_f1: 0.857015, valid_f1: 0.895797\n",
      "--- 35.20012974739075 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435996\n",
      "train_loss: 0.101388, valid_loss: 0.106383\n",
      "train_f1: 0.859324, valid_f1: 0.897645\n",
      "--- 35.420557498931885 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000424475\n",
      "train_loss: 0.101354, valid_loss: 0.105672\n",
      "train_f1: 0.861165, valid_f1: 0.896560\n",
      "--- 35.50695252418518 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412994\n",
      "train_loss: 0.100416, valid_loss: 0.108494\n",
      "train_f1: 0.862090, valid_f1: 0.891766\n",
      "--- 35.62850499153137 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000401561\n",
      "train_loss: 0.098615, valid_loss: 0.108039\n",
      "train_f1: 0.863868, valid_f1: 0.894435\n",
      "--- 35.42175221443176 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000390181\n",
      "train_loss: 0.098130, valid_loss: 0.103024\n",
      "train_f1: 0.865546, valid_f1: 0.899118\n",
      "--- 35.7344491481781 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000378860\n",
      "train_loss: 0.099479, valid_loss: 0.086547\n",
      "train_f1: 0.863377, valid_f1: 0.899848\n",
      "--- 35.30322861671448 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000367605\n",
      "train_loss: 0.097327, valid_loss: 0.106736\n",
      "train_f1: 0.867730, valid_f1: 0.897565\n",
      "--- 35.676785707473755 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000356422\n",
      "train_loss: 0.096998, valid_loss: 0.105911\n",
      "train_f1: 0.867709, valid_f1: 0.899467\n",
      "--- 35.25763726234436 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000345316\n",
      "train_loss: 0.096903, valid_loss: 0.104446\n",
      "train_f1: 0.868404, valid_f1: 0.898439\n",
      "--- 35.182637453079224 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000334294\n",
      "train_loss: 0.097192, valid_loss: 0.104951\n",
      "train_f1: 0.868084, valid_f1: 0.900174\n",
      "--- 35.552454233169556 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000323362\n",
      "train_loss: 0.095591, valid_loss: 0.107466\n",
      "train_f1: 0.869757, valid_f1: 0.896506\n",
      "--- 35.06041502952576 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000312526\n",
      "train_loss: 0.109936, valid_loss: 0.110676\n",
      "train_f1: 0.867240, valid_f1: 0.893185\n",
      "--- 35.41283440589905 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000301791\n",
      "train_loss: 0.099438, valid_loss: 0.103213\n",
      "train_f1: 0.867997, valid_f1: 0.894942\n",
      "--- 35.13367009162903 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000291163\n",
      "train_loss: 0.108562, valid_loss: 0.101393\n",
      "train_f1: 0.864595, valid_f1: 0.887944\n",
      "--- 34.80360198020935 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000280649\n",
      "train_loss: 0.128331, valid_loss: 0.092526\n",
      "train_f1: 0.840649, valid_f1: 0.884642\n",
      "--- 35.49933195114136 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000270253\n",
      "train_loss: 0.105021, valid_loss: 0.123411\n",
      "train_f1: 0.861105, valid_f1: 0.882610\n",
      "--- 35.420982122421265 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259981\n",
      "train_loss: 0.121639, valid_loss: 0.087242\n",
      "train_f1: 0.841704, valid_f1: 0.893888\n",
      "--- 34.673200368881226 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000249840\n",
      "train_loss: 0.098244, valid_loss: 0.085203\n",
      "train_f1: 0.865747, valid_f1: 0.899422\n",
      "--- 35.55891013145447 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239834\n",
      "train_loss: 0.095865, valid_loss: 0.084631\n",
      "train_f1: 0.869630, valid_f1: 0.900476\n",
      "--- 35.45627284049988 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229969\n",
      "train_loss: 0.095797, valid_loss: 0.085154\n",
      "train_f1: 0.871801, valid_f1: 0.898197\n",
      "--- 35.4164764881134 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.000220251\n",
      "train_loss: 0.095142, valid_loss: 0.084058\n",
      "train_f1: 0.872873, valid_f1: 0.901868\n",
      "--- 35.15635323524475 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.000210683\n",
      "train_loss: 0.094527, valid_loss: 0.085434\n",
      "train_f1: 0.873226, valid_f1: 0.902358\n",
      "--- 35.34247946739197 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.000201273\n",
      "train_loss: 0.094112, valid_loss: 0.086682\n",
      "train_f1: 0.873685, valid_f1: 0.901884\n",
      "--- 35.42337656021118 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.000192024\n",
      "train_loss: 0.094221, valid_loss: 0.084304\n",
      "train_f1: 0.874197, valid_f1: 0.901971\n",
      "--- 35.182727575302124 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.000182942\n",
      "train_loss: 0.093953, valid_loss: 0.085867\n",
      "train_f1: 0.874130, valid_f1: 0.901061\n",
      "--- 35.262534379959106 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.000174031\n",
      "train_loss: 0.093383, valid_loss: 0.084857\n",
      "train_f1: 0.874610, valid_f1: 0.900075\n",
      "--- 35.63050985336304 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.000165298\n",
      "train_loss: 0.092885, valid_loss: 0.086982\n",
      "train_f1: 0.875193, valid_f1: 0.902224\n",
      "--- 35.66645097732544 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.000156745\n",
      "train_loss: 0.092516, valid_loss: 0.085800\n",
      "train_f1: 0.875780, valid_f1: 0.899826\n",
      "--- 35.209428548812866 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.000148378\n",
      "train_loss: 0.092774, valid_loss: 0.084781\n",
      "train_f1: 0.875776, valid_f1: 0.903422\n",
      "--- 35.544729232788086 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.000140202\n",
      "train_loss: 0.092077, valid_loss: 0.087642\n",
      "train_f1: 0.876242, valid_f1: 0.901006\n",
      "--- 35.30995559692383 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.000132220\n",
      "train_loss: 0.092376, valid_loss: 0.085165\n",
      "train_f1: 0.876830, valid_f1: 0.903653\n",
      "--- 35.48805212974548 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.000124438\n",
      "train_loss: 0.091939, valid_loss: 0.082399\n",
      "train_f1: 0.876490, valid_f1: 0.903456\n",
      "--- 35.140376329422 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.000116859\n",
      "train_loss: 0.091914, valid_loss: 0.084247\n",
      "train_f1: 0.876652, valid_f1: 0.903548\n",
      "--- 35.42357635498047 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.000109488\n",
      "train_loss: 0.092010, valid_loss: 0.084257\n",
      "train_f1: 0.877013, valid_f1: 0.903104\n",
      "--- 35.67810559272766 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.000102328\n",
      "train_loss: 0.091990, valid_loss: 0.094584\n",
      "train_f1: 0.877380, valid_f1: 0.902334\n",
      "--- 35.57907557487488 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000095383\n",
      "train_loss: 0.091600, valid_loss: 0.086009\n",
      "train_f1: 0.877249, valid_f1: 0.902577\n",
      "--- 35.40683627128601 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000088658\n",
      "train_loss: 0.091264, valid_loss: 0.082850\n",
      "train_f1: 0.878204, valid_f1: 0.903613\n",
      "--- 35.87115669250488 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000082155\n",
      "train_loss: 0.091594, valid_loss: 0.081159\n",
      "train_f1: 0.877965, valid_f1: 0.905212\n",
      "--- 35.410828828811646 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000075878\n",
      "train_loss: 0.091276, valid_loss: 0.090947\n",
      "train_f1: 0.877684, valid_f1: 0.903060\n",
      "--- 34.61170768737793 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000069831\n",
      "train_loss: 0.091000, valid_loss: 0.084472\n",
      "train_f1: 0.878199, valid_f1: 0.903944\n",
      "--- 35.42769503593445 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000064017\n",
      "train_loss: 0.090349, valid_loss: 0.080560\n",
      "train_f1: 0.877662, valid_f1: 0.904065\n",
      "--- 35.55417585372925 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000058440\n",
      "train_loss: 0.091507, valid_loss: 0.083781\n",
      "train_f1: 0.877813, valid_f1: 0.904039\n",
      "--- 34.78868389129639 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000053101\n",
      "train_loss: 0.091062, valid_loss: 0.082663\n",
      "train_f1: 0.878209, valid_f1: 0.904546\n",
      "--- 35.06954741477966 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000048004\n",
      "train_loss: 0.090671, valid_loss: 0.084539\n",
      "train_f1: 0.878645, valid_f1: 0.904031\n",
      "--- 35.49534821510315 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000043152\n",
      "train_loss: 0.090886, valid_loss: 0.093230\n",
      "train_f1: 0.878423, valid_f1: 0.902767\n",
      "--- 35.12876868247986 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000038548\n",
      "train_loss: 0.091118, valid_loss: 0.091660\n",
      "train_f1: 0.878629, valid_f1: 0.903407\n",
      "--- 35.09966778755188 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000034193\n",
      "train_loss: 0.090337, valid_loss: 0.085731\n",
      "train_f1: 0.878924, valid_f1: 0.903259\n",
      "--- 35.24559044837952 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000030091\n",
      "train_loss: 0.090216, valid_loss: 0.093110\n",
      "train_f1: 0.879370, valid_f1: 0.903204\n",
      "--- 35.48963499069214 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000026243\n",
      "train_loss: 0.090720, valid_loss: 0.092332\n",
      "train_f1: 0.878877, valid_f1: 0.902955\n",
      "--- 35.84665632247925 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000022651\n",
      "train_loss: 0.089832, valid_loss: 0.090929\n",
      "train_f1: 0.879076, valid_f1: 0.903242\n",
      "--- 35.338571310043335 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000019318\n",
      "train_loss: 0.090291, valid_loss: 0.081372\n",
      "train_f1: 0.878914, valid_f1: 0.905297\n",
      "--- 35.24588418006897 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000016246\n",
      "train_loss: 0.090194, valid_loss: 0.082838\n",
      "train_f1: 0.879511, valid_f1: 0.904685\n",
      "--- 35.23219347000122 seconds ---\n",
      "Epoch : 140\n",
      "learning_rate: 0.000013435\n",
      "train_loss: 0.090597, valid_loss: 0.083615\n",
      "train_f1: 0.879374, valid_f1: 0.904326\n",
      "--- 35.16299271583557 seconds ---\n",
      "Epoch : 141\n",
      "learning_rate: 0.000010888\n",
      "train_loss: 0.090601, valid_loss: 0.090736\n",
      "train_f1: 0.879237, valid_f1: 0.903383\n",
      "--- 35.789342164993286 seconds ---\n",
      "Epoch : 142\n",
      "learning_rate: 0.000008606\n",
      "train_loss: 0.090648, valid_loss: 0.087143\n",
      "train_f1: 0.879166, valid_f1: 0.903401\n",
      "--- 35.050536155700684 seconds ---\n",
      "Epoch : 143\n",
      "learning_rate: 0.000006589\n",
      "train_loss: 0.090250, valid_loss: 0.085962\n",
      "train_f1: 0.879461, valid_f1: 0.903836\n",
      "--- 35.12636160850525 seconds ---\n",
      "Epoch : 144\n",
      "learning_rate: 0.000004840\n",
      "train_loss: 0.089877, valid_loss: 0.091661\n",
      "train_f1: 0.879547, valid_f1: 0.903212\n",
      "--- 35.15577435493469 seconds ---\n",
      "Epoch : 145\n",
      "learning_rate: 0.000003360\n",
      "train_loss: 0.089787, valid_loss: 0.085178\n",
      "train_f1: 0.879495, valid_f1: 0.904044\n",
      "--- 35.16358709335327 seconds ---\n",
      "Epoch : 146\n",
      "learning_rate: 0.000002148\n",
      "train_loss: 0.090472, valid_loss: 0.085649\n",
      "train_f1: 0.879388, valid_f1: 0.903887\n",
      "--- 35.168752908706665 seconds ---\n",
      "Epoch : 147\n",
      "learning_rate: 0.000001205\n",
      "train_loss: 0.090060, valid_loss: 0.085001\n",
      "train_f1: 0.879209, valid_f1: 0.904098\n",
      "--- 35.007490396499634 seconds ---\n",
      "Epoch : 148\n",
      "learning_rate: 0.000000533\n",
      "train_loss: 0.090182, valid_loss: 0.084889\n",
      "train_f1: 0.879485, valid_f1: 0.904143\n",
      "--- 35.34263372421265 seconds ---\n",
      "Epoch : 149\n",
      "learning_rate: 0.000000131\n",
      "train_loss: 0.089878, valid_loss: 0.084875\n",
      "train_f1: 0.879153, valid_f1: 0.904149\n",
      "--- 35.16013526916504 seconds ---\n",
      "Fold : 4\n",
      "Epoch : 0\n",
      "learning_rate: 0.000001000\n",
      "train_loss: 2.056105, valid_loss: 1.865695\n",
      "train_f1: 0.055331, valid_f1: 0.006830\n",
      "--- 35.68112373352051 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000011938\n",
      "train_loss: 1.915414, valid_loss: 1.667477\n",
      "train_f1: 0.060135, valid_f1: 0.021326\n",
      "--- 35.916574478149414 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000044274\n",
      "train_loss: 1.617618, valid_loss: 1.179753\n",
      "train_f1: 0.078576, valid_f1: 0.051764\n",
      "--- 35.64770436286926 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000096592\n",
      "train_loss: 1.210051, valid_loss: 0.794001\n",
      "train_f1: 0.103142, valid_f1: 0.113828\n",
      "--- 35.48203706741333 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000166599\n",
      "train_loss: 0.946269, valid_loss: 0.689144\n",
      "train_f1: 0.139301, valid_f1: 0.118474\n",
      "--- 35.67170691490173 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000251230\n",
      "train_loss: 0.819911, valid_loss: 0.660103\n",
      "train_f1: 0.163757, valid_f1: 0.176353\n",
      "--- 35.51304793357849 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000346779\n",
      "train_loss: 0.740088, valid_loss: 0.621761\n",
      "train_f1: 0.188754, valid_f1: 0.191487\n",
      "--- 35.190141916275024 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000449060\n",
      "train_loss: 0.691905, valid_loss: 0.602468\n",
      "train_f1: 0.202389, valid_f1: 0.200727\n",
      "--- 35.57807946205139 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000553594\n",
      "train_loss: 0.658758, valid_loss: 0.584831\n",
      "train_f1: 0.214878, valid_f1: 0.212277\n",
      "--- 35.51656484603882 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000655802\n",
      "train_loss: 0.633334, valid_loss: 0.573348\n",
      "train_f1: 0.221383, valid_f1: 0.236175\n",
      "--- 35.66004943847656 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000751209\n",
      "train_loss: 0.608773, valid_loss: 0.550214\n",
      "train_f1: 0.236530, valid_f1: 0.261512\n",
      "--- 35.40826392173767 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000835636\n",
      "train_loss: 0.574046, valid_loss: 0.504129\n",
      "train_f1: 0.265147, valid_f1: 0.294370\n",
      "--- 35.72755813598633 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000905384\n",
      "train_loss: 0.536367, valid_loss: 0.486106\n",
      "train_f1: 0.293322, valid_f1: 0.298752\n",
      "--- 35.522499322891235 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000957400\n",
      "train_loss: 0.505268, valid_loss: 0.433872\n",
      "train_f1: 0.322083, valid_f1: 0.360492\n",
      "--- 35.47580075263977 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000989405\n",
      "train_loss: 0.473077, valid_loss: 0.423392\n",
      "train_f1: 0.354938, valid_f1: 0.337677\n",
      "--- 35.17347598075867 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.001000000\n",
      "train_loss: 0.455817, valid_loss: 0.371890\n",
      "train_f1: 0.376182, valid_f1: 0.421241\n",
      "--- 34.980018854141235 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999860\n",
      "train_loss: 0.413013, valid_loss: 0.335417\n",
      "train_f1: 0.419778, valid_f1: 0.470411\n",
      "--- 35.38815093040466 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999450\n",
      "train_loss: 0.392289, valid_loss: 0.312738\n",
      "train_f1: 0.446844, valid_f1: 0.496260\n",
      "--- 34.99882245063782 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998769\n",
      "train_loss: 0.364095, valid_loss: 0.287403\n",
      "train_f1: 0.480027, valid_f1: 0.603985\n",
      "--- 35.216066122055054 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997818\n",
      "train_loss: 0.341874, valid_loss: 0.262486\n",
      "train_f1: 0.504508, valid_f1: 0.571008\n",
      "--- 35.212430238723755 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996598\n",
      "train_loss: 0.324071, valid_loss: 0.288718\n",
      "train_f1: 0.530671, valid_f1: 0.592890\n",
      "--- 35.35670757293701 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000995108\n",
      "train_loss: 0.310525, valid_loss: 0.237798\n",
      "train_f1: 0.548446, valid_f1: 0.665247\n",
      "--- 35.03145742416382 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993351\n",
      "train_loss: 0.295264, valid_loss: 0.246518\n",
      "train_f1: 0.572660, valid_f1: 0.671109\n",
      "--- 35.57349872589111 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991326\n",
      "train_loss: 0.288910, valid_loss: 0.214679\n",
      "train_f1: 0.580502, valid_f1: 0.716541\n",
      "--- 35.030094146728516 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000989035\n",
      "train_loss: 0.269649, valid_loss: 0.209275\n",
      "train_f1: 0.605666, valid_f1: 0.722746\n",
      "--- 35.247443199157715 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986480\n",
      "train_loss: 0.263142, valid_loss: 0.188896\n",
      "train_f1: 0.616691, valid_f1: 0.737239\n",
      "--- 34.98215317726135 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983661\n",
      "train_loss: 0.252218, valid_loss: 0.184170\n",
      "train_f1: 0.633008, valid_f1: 0.744610\n",
      "--- 35.49844717979431 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980580\n",
      "train_loss: 0.273971, valid_loss: 0.184532\n",
      "train_f1: 0.610476, valid_f1: 0.723880\n",
      "--- 35.110010385513306 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000977239\n",
      "train_loss: 0.235733, valid_loss: 0.165208\n",
      "train_f1: 0.650925, valid_f1: 0.763134\n",
      "--- 34.17653942108154 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973639\n",
      "train_loss: 0.224045, valid_loss: 0.157315\n",
      "train_f1: 0.670113, valid_f1: 0.767141\n",
      "--- 35.173091411590576 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969783\n",
      "train_loss: 0.216923, valid_loss: 0.153758\n",
      "train_f1: 0.680361, valid_f1: 0.771878\n",
      "--- 35.189833641052246 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965673\n",
      "train_loss: 0.211544, valid_loss: 0.143820\n",
      "train_f1: 0.685653, valid_f1: 0.779670\n",
      "--- 35.402260541915894 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000961310\n",
      "train_loss: 0.199253, valid_loss: 0.143290\n",
      "train_f1: 0.698911, valid_f1: 0.784576\n",
      "--- 34.98813509941101 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956698\n",
      "train_loss: 0.197650, valid_loss: 0.149539\n",
      "train_f1: 0.706189, valid_f1: 0.765419\n",
      "--- 35.43106198310852 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951838\n",
      "train_loss: 0.190854, valid_loss: 0.156347\n",
      "train_f1: 0.711629, valid_f1: 0.743117\n",
      "--- 35.51506781578064 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946733\n",
      "train_loss: 0.198956, valid_loss: 0.134146\n",
      "train_f1: 0.703571, valid_f1: 0.786494\n",
      "--- 35.487425327301025 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000941387\n",
      "train_loss: 0.183383, valid_loss: 0.134724\n",
      "train_f1: 0.720720, valid_f1: 0.769383\n",
      "--- 35.49164175987244 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935802\n",
      "train_loss: 0.177057, valid_loss: 0.125057\n",
      "train_f1: 0.726798, valid_f1: 0.794321\n",
      "--- 35.39199638366699 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929980\n",
      "train_loss: 0.171883, valid_loss: 0.115026\n",
      "train_f1: 0.736372, valid_f1: 0.797530\n",
      "--- 35.60974359512329 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923926\n",
      "train_loss: 0.169575, valid_loss: 0.112375\n",
      "train_f1: 0.737711, valid_f1: 0.803061\n",
      "--- 34.56106781959534 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917642\n",
      "train_loss: 0.176266, valid_loss: 0.148658\n",
      "train_f1: 0.735645, valid_f1: 0.769993\n",
      "--- 35.48181986808777 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000911132\n",
      "train_loss: 0.177060, valid_loss: 0.114438\n",
      "train_f1: 0.734380, valid_f1: 0.797110\n",
      "--- 35.11004900932312 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000904400\n",
      "train_loss: 0.154783, valid_loss: 0.117439\n",
      "train_f1: 0.752939, valid_f1: 0.791517\n",
      "--- 35.69002389907837 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000897448\n",
      "train_loss: 0.161638, valid_loss: 0.112307\n",
      "train_f1: 0.750598, valid_f1: 0.797804\n",
      "--- 35.06507158279419 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000890282\n",
      "train_loss: 0.148121, valid_loss: 0.104252\n",
      "train_f1: 0.761855, valid_f1: 0.804398\n",
      "--- 35.26126980781555 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882903\n",
      "train_loss: 0.170502, valid_loss: 0.117063\n",
      "train_f1: 0.742998, valid_f1: 0.798269\n",
      "--- 35.72817373275757 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000875318\n",
      "train_loss: 0.149467, valid_loss: 0.100314\n",
      "train_f1: 0.763497, valid_f1: 0.807625\n",
      "--- 35.10199427604675 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000867529\n",
      "train_loss: 0.142402, valid_loss: 0.099544\n",
      "train_f1: 0.769389, valid_f1: 0.809140\n",
      "--- 35.302133083343506 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000859542\n",
      "train_loss: 0.140238, valid_loss: 0.100746\n",
      "train_f1: 0.771915, valid_f1: 0.811296\n",
      "--- 35.09447407722473 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000851359\n",
      "train_loss: 0.136388, valid_loss: 0.095736\n",
      "train_f1: 0.776949, valid_f1: 0.811868\n",
      "--- 35.16388750076294 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842986\n",
      "train_loss: 0.133820, valid_loss: 0.093136\n",
      "train_f1: 0.779920, valid_f1: 0.812680\n",
      "--- 35.22342395782471 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000834428\n",
      "train_loss: 0.132563, valid_loss: 0.096715\n",
      "train_f1: 0.780800, valid_f1: 0.810892\n",
      "--- 35.339868783950806 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000825689\n",
      "train_loss: 0.133538, valid_loss: 0.096294\n",
      "train_f1: 0.780420, valid_f1: 0.809415\n",
      "--- 35.58358097076416 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816773\n",
      "train_loss: 0.132043, valid_loss: 0.093028\n",
      "train_f1: 0.782769, valid_f1: 0.811370\n",
      "--- 35.258915424346924 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000807685\n",
      "train_loss: 0.128332, valid_loss: 0.113844\n",
      "train_f1: 0.787545, valid_f1: 0.801481\n",
      "--- 34.86937141418457 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000798431\n",
      "train_loss: 0.131974, valid_loss: 0.091133\n",
      "train_f1: 0.786436, valid_f1: 0.812625\n",
      "--- 33.886510133743286 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000789015\n",
      "train_loss: 0.125393, valid_loss: 0.088879\n",
      "train_f1: 0.792613, valid_f1: 0.814092\n",
      "--- 35.13164305686951 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000779443\n",
      "train_loss: 0.124667, valid_loss: 0.111362\n",
      "train_f1: 0.794711, valid_f1: 0.800293\n",
      "--- 34.41141128540039 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000769720\n",
      "train_loss: 0.127462, valid_loss: 0.088440\n",
      "train_f1: 0.793372, valid_f1: 0.816650\n",
      "--- 34.513161420822144 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759850\n",
      "train_loss: 0.120156, valid_loss: 0.087442\n",
      "train_f1: 0.799882, valid_f1: 0.814369\n",
      "--- 35.28458070755005 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000749840\n",
      "train_loss: 0.119223, valid_loss: 0.086882\n",
      "train_f1: 0.802403, valid_f1: 0.815842\n",
      "--- 35.73535990715027 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000739695\n",
      "train_loss: 0.148367, valid_loss: 0.093942\n",
      "train_f1: 0.780227, valid_f1: 0.810754\n",
      "--- 35.94001245498657 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000729419\n",
      "train_loss: 0.126605, valid_loss: 0.091732\n",
      "train_f1: 0.795527, valid_f1: 0.811400\n",
      "--- 35.42476558685303 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000719020\n",
      "train_loss: 0.118977, valid_loss: 0.087044\n",
      "train_f1: 0.802431, valid_f1: 0.814657\n",
      "--- 35.49675893783569 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000708501\n",
      "train_loss: 0.117301, valid_loss: 0.085554\n",
      "train_f1: 0.805627, valid_f1: 0.818044\n",
      "--- 35.29830980300903 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000697870\n",
      "train_loss: 0.116641, valid_loss: 0.084411\n",
      "train_f1: 0.807375, valid_f1: 0.818550\n",
      "--- 35.36308717727661 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000687132\n",
      "train_loss: 0.114837, valid_loss: 0.083411\n",
      "train_f1: 0.812349, valid_f1: 0.819039\n",
      "--- 36.023998498916626 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000676292\n",
      "train_loss: 0.113155, valid_loss: 0.084240\n",
      "train_f1: 0.815187, valid_f1: 0.815474\n",
      "--- 35.133569955825806 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000665357\n",
      "train_loss: 0.120390, valid_loss: 0.097976\n",
      "train_f1: 0.811245, valid_f1: 0.805516\n",
      "--- 35.68019390106201 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000654333\n",
      "train_loss: 0.114598, valid_loss: 0.082821\n",
      "train_f1: 0.816376, valid_f1: 0.818534\n",
      "--- 35.83346724510193 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000643225\n",
      "train_loss: 0.111873, valid_loss: 0.081099\n",
      "train_f1: 0.819722, valid_f1: 0.821166\n",
      "--- 35.480353593826294 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000632039\n",
      "train_loss: 0.111066, valid_loss: 0.080468\n",
      "train_f1: 0.822135, valid_f1: 0.820810\n",
      "--- 35.127068281173706 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000620782\n",
      "train_loss: 0.109583, valid_loss: 0.079854\n",
      "train_f1: 0.825423, valid_f1: 0.820325\n",
      "--- 35.495959520339966 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000609459\n",
      "train_loss: 0.109343, valid_loss: 0.078971\n",
      "train_f1: 0.827130, valid_f1: 0.823036\n",
      "--- 35.22779679298401 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000598077\n",
      "train_loss: 0.107936, valid_loss: 0.081992\n",
      "train_f1: 0.829545, valid_f1: 0.818296\n",
      "--- 35.47883486747742 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000586642\n",
      "train_loss: 0.106253, valid_loss: 0.083525\n",
      "train_f1: 0.831904, valid_f1: 0.816585\n",
      "--- 35.18951463699341 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000575160\n",
      "train_loss: 0.106953, valid_loss: 0.079934\n",
      "train_f1: 0.834783, valid_f1: 0.823707\n",
      "--- 35.43329191207886 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000563638\n",
      "train_loss: 0.111351, valid_loss: 0.079219\n",
      "train_f1: 0.830391, valid_f1: 0.821396\n",
      "--- 35.49194645881653 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000552081\n",
      "train_loss: 0.105400, valid_loss: 0.077913\n",
      "train_f1: 0.836973, valid_f1: 0.824418\n",
      "--- 35.012789487838745 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000540495\n",
      "train_loss: 0.104699, valid_loss: 0.080485\n",
      "train_f1: 0.840785, valid_f1: 0.864031\n",
      "--- 35.4558207988739 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000528888\n",
      "train_loss: 0.103873, valid_loss: 0.076038\n",
      "train_f1: 0.841678, valid_f1: 0.879936\n",
      "--- 34.531044483184814 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000517265\n",
      "train_loss: 0.102966, valid_loss: 0.075492\n",
      "train_f1: 0.844804, valid_f1: 0.883236\n",
      "--- 35.620869398117065 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000505633\n",
      "train_loss: 0.102545, valid_loss: 0.077613\n",
      "train_f1: 0.846549, valid_f1: 0.884459\n",
      "--- 34.36982560157776 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493998\n",
      "train_loss: 0.101383, valid_loss: 0.078085\n",
      "train_f1: 0.849161, valid_f1: 0.884912\n",
      "--- 35.279625415802 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000482366\n",
      "train_loss: 0.101506, valid_loss: 0.082008\n",
      "train_f1: 0.851209, valid_f1: 0.882213\n",
      "--- 35.57532978057861 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000470743\n",
      "train_loss: 0.102210, valid_loss: 0.077773\n",
      "train_f1: 0.851057, valid_f1: 0.899819\n",
      "--- 35.39557647705078 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000459137\n",
      "train_loss: 0.101494, valid_loss: 0.076599\n",
      "train_f1: 0.851786, valid_f1: 0.902801\n",
      "--- 35.08793759346008 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000447552\n",
      "train_loss: 0.099851, valid_loss: 0.073920\n",
      "train_f1: 0.854983, valid_f1: 0.905255\n",
      "--- 35.142985820770264 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435996\n",
      "train_loss: 0.098858, valid_loss: 0.073634\n",
      "train_f1: 0.858728, valid_f1: 0.903147\n",
      "--- 35.528449058532715 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000424475\n",
      "train_loss: 0.098921, valid_loss: 0.073267\n",
      "train_f1: 0.858549, valid_f1: 0.903754\n",
      "--- 35.25685501098633 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412994\n",
      "train_loss: 0.099192, valid_loss: 0.073223\n",
      "train_f1: 0.857876, valid_f1: 0.906774\n",
      "--- 35.10230326652527 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000401561\n",
      "train_loss: 0.098229, valid_loss: 0.076539\n",
      "train_f1: 0.860168, valid_f1: 0.900730\n",
      "--- 35.315855264663696 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000390181\n",
      "train_loss: 0.097254, valid_loss: 0.072917\n",
      "train_f1: 0.860822, valid_f1: 0.906090\n",
      "--- 35.459415435791016 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000378860\n",
      "train_loss: 0.097204, valid_loss: 0.072859\n",
      "train_f1: 0.863346, valid_f1: 0.905737\n",
      "--- 35.31601548194885 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000367605\n",
      "train_loss: 0.097026, valid_loss: 0.071811\n",
      "train_f1: 0.863579, valid_f1: 0.908131\n",
      "--- 34.84380555152893 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000356422\n",
      "train_loss: 0.096524, valid_loss: 0.071730\n",
      "train_f1: 0.865736, valid_f1: 0.908750\n",
      "--- 35.101876735687256 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000345316\n",
      "train_loss: 0.094797, valid_loss: 0.070710\n",
      "train_f1: 0.866915, valid_f1: 0.909880\n",
      "--- 35.55595326423645 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000334294\n",
      "train_loss: 0.095130, valid_loss: 0.070765\n",
      "train_f1: 0.867831, valid_f1: 0.909788\n",
      "--- 35.432217597961426 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000323362\n",
      "train_loss: 0.095181, valid_loss: 0.071867\n",
      "train_f1: 0.866981, valid_f1: 0.908503\n",
      "--- 35.54811501502991 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000312526\n",
      "train_loss: 0.094578, valid_loss: 0.071874\n",
      "train_f1: 0.868586, valid_f1: 0.908891\n",
      "--- 35.22558546066284 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000301791\n",
      "train_loss: 0.094163, valid_loss: 0.071163\n",
      "train_f1: 0.869934, valid_f1: 0.909467\n",
      "--- 35.52227830886841 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000291163\n",
      "train_loss: 0.094212, valid_loss: 0.071856\n",
      "train_f1: 0.871031, valid_f1: 0.907183\n",
      "--- 35.48250126838684 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000280649\n",
      "train_loss: 0.093482, valid_loss: 0.070261\n",
      "train_f1: 0.871400, valid_f1: 0.910967\n",
      "--- 35.3040816783905 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000270253\n",
      "train_loss: 0.093223, valid_loss: 0.070062\n",
      "train_f1: 0.871518, valid_f1: 0.910266\n",
      "--- 35.01556062698364 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259981\n",
      "train_loss: 0.092840, valid_loss: 0.070401\n",
      "train_f1: 0.872689, valid_f1: 0.909858\n",
      "--- 35.1308970451355 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000249840\n",
      "train_loss: 0.093143, valid_loss: 0.070283\n",
      "train_f1: 0.873413, valid_f1: 0.910151\n",
      "--- 35.23546743392944 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239834\n",
      "train_loss: 0.095267, valid_loss: 0.073340\n",
      "train_f1: 0.873418, valid_f1: 0.908936\n",
      "--- 35.795321226119995 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229969\n",
      "train_loss: 0.092377, valid_loss: 0.070964\n",
      "train_f1: 0.874278, valid_f1: 0.908770\n",
      "--- 35.27612638473511 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.000220251\n",
      "train_loss: 0.091802, valid_loss: 0.071209\n",
      "train_f1: 0.874816, valid_f1: 0.908261\n",
      "--- 35.181572914123535 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.000210683\n",
      "train_loss: 0.092346, valid_loss: 0.069434\n",
      "train_f1: 0.874502, valid_f1: 0.911077\n",
      "--- 35.16893482208252 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.000201273\n",
      "train_loss: 0.091018, valid_loss: 0.068812\n",
      "train_f1: 0.876859, valid_f1: 0.912307\n",
      "--- 35.397924184799194 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.000192024\n",
      "train_loss: 0.090984, valid_loss: 0.069929\n",
      "train_f1: 0.875638, valid_f1: 0.910406\n",
      "--- 35.031747341156006 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.000182942\n",
      "train_loss: 0.090868, valid_loss: 0.068542\n",
      "train_f1: 0.876470, valid_f1: 0.912717\n",
      "--- 35.36192202568054 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.000174031\n",
      "train_loss: 0.090463, valid_loss: 0.068341\n",
      "train_f1: 0.876713, valid_f1: 0.912247\n",
      "--- 35.34286689758301 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.000165298\n",
      "train_loss: 0.089682, valid_loss: 0.069355\n",
      "train_f1: 0.877643, valid_f1: 0.910785\n",
      "--- 35.18305730819702 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.000156745\n",
      "train_loss: 0.090028, valid_loss: 0.068246\n",
      "train_f1: 0.877622, valid_f1: 0.912434\n",
      "--- 35.13464617729187 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.000148378\n",
      "train_loss: 0.090223, valid_loss: 0.070379\n",
      "train_f1: 0.877782, valid_f1: 0.908613\n",
      "--- 35.38749170303345 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.000140202\n",
      "train_loss: 0.090140, valid_loss: 0.069955\n",
      "train_f1: 0.878558, valid_f1: 0.910566\n",
      "--- 35.47528839111328 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.000132220\n",
      "train_loss: 0.089418, valid_loss: 0.067893\n",
      "train_f1: 0.879042, valid_f1: 0.913154\n",
      "--- 35.492844581604004 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.000124438\n",
      "train_loss: 0.089212, valid_loss: 0.068322\n",
      "train_f1: 0.879973, valid_f1: 0.913182\n",
      "--- 35.07759213447571 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.000116859\n",
      "train_loss: 0.088609, valid_loss: 0.068011\n",
      "train_f1: 0.879962, valid_f1: 0.913321\n",
      "--- 34.80546259880066 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.000109488\n",
      "train_loss: 0.089082, valid_loss: 0.068677\n",
      "train_f1: 0.880053, valid_f1: 0.912438\n",
      "--- 35.52440118789673 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.000102328\n",
      "train_loss: 0.088479, valid_loss: 0.068973\n",
      "train_f1: 0.880248, valid_f1: 0.912155\n",
      "--- 35.49435305595398 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000095383\n",
      "train_loss: 0.088187, valid_loss: 0.067500\n",
      "train_f1: 0.880906, valid_f1: 0.913734\n",
      "--- 35.29345202445984 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000088658\n",
      "train_loss: 0.088168, valid_loss: 0.067615\n",
      "train_f1: 0.881282, valid_f1: 0.913650\n",
      "--- 35.10713076591492 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000082155\n",
      "train_loss: 0.088445, valid_loss: 0.067627\n",
      "train_f1: 0.881154, valid_f1: 0.914022\n",
      "--- 35.452880859375 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000075878\n",
      "train_loss: 0.087803, valid_loss: 0.067867\n",
      "train_f1: 0.881179, valid_f1: 0.913392\n",
      "--- 34.41353631019592 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000069831\n",
      "train_loss: 0.087934, valid_loss: 0.067352\n",
      "train_f1: 0.881651, valid_f1: 0.914134\n",
      "--- 35.06275510787964 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000064017\n",
      "train_loss: 0.087519, valid_loss: 0.067673\n",
      "train_f1: 0.881762, valid_f1: 0.913719\n",
      "--- 35.36258029937744 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000058440\n",
      "train_loss: 0.087750, valid_loss: 0.067189\n",
      "train_f1: 0.881824, valid_f1: 0.914332\n",
      "--- 36.02893257141113 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000053101\n",
      "train_loss: 0.087755, valid_loss: 0.068576\n",
      "train_f1: 0.881996, valid_f1: 0.912442\n",
      "--- 34.69845199584961 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000048004\n",
      "train_loss: 0.088155, valid_loss: 0.067364\n",
      "train_f1: 0.881699, valid_f1: 0.913987\n",
      "--- 35.88910174369812 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000043152\n",
      "train_loss: 0.087844, valid_loss: 0.067023\n",
      "train_f1: 0.882475, valid_f1: 0.914559\n",
      "--- 34.566832065582275 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000038548\n",
      "train_loss: 0.087744, valid_loss: 0.067344\n",
      "train_f1: 0.882175, valid_f1: 0.914223\n",
      "--- 35.101412773132324 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000034193\n",
      "train_loss: 0.087493, valid_loss: 0.067094\n",
      "train_f1: 0.882423, valid_f1: 0.914328\n",
      "--- 35.4833550453186 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000030091\n",
      "train_loss: 0.086951, valid_loss: 0.067483\n",
      "train_f1: 0.882264, valid_f1: 0.913964\n",
      "--- 35.39074754714966 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000026243\n",
      "train_loss: 0.087469, valid_loss: 0.067291\n",
      "train_f1: 0.882449, valid_f1: 0.914212\n",
      "--- 35.43896532058716 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000022651\n",
      "train_loss: 0.087673, valid_loss: 0.066777\n",
      "train_f1: 0.882782, valid_f1: 0.914980\n",
      "--- 35.44624400138855 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000019318\n",
      "train_loss: 0.087296, valid_loss: 0.066832\n",
      "train_f1: 0.882557, valid_f1: 0.914879\n",
      "--- 34.94111371040344 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000016246\n",
      "train_loss: 0.087161, valid_loss: 0.067286\n",
      "train_f1: 0.883005, valid_f1: 0.914268\n",
      "--- 35.27531599998474 seconds ---\n",
      "Epoch : 140\n",
      "learning_rate: 0.000013435\n",
      "train_loss: 0.086915, valid_loss: 0.067064\n",
      "train_f1: 0.883090, valid_f1: 0.914584\n",
      "--- 34.652453899383545 seconds ---\n",
      "Epoch : 141\n",
      "learning_rate: 0.000010888\n",
      "train_loss: 0.087170, valid_loss: 0.066948\n",
      "train_f1: 0.882795, valid_f1: 0.914480\n",
      "--- 35.53962254524231 seconds ---\n",
      "Epoch : 142\n",
      "learning_rate: 0.000008606\n",
      "train_loss: 0.086735, valid_loss: 0.067044\n",
      "train_f1: 0.882690, valid_f1: 0.914557\n",
      "--- 35.471718072891235 seconds ---\n",
      "Epoch : 143\n",
      "learning_rate: 0.000006589\n",
      "train_loss: 0.086904, valid_loss: 0.067061\n",
      "train_f1: 0.882869, valid_f1: 0.914573\n",
      "--- 35.422746658325195 seconds ---\n",
      "Epoch : 144\n",
      "learning_rate: 0.000004840\n",
      "train_loss: 0.086902, valid_loss: 0.067057\n",
      "train_f1: 0.882505, valid_f1: 0.914575\n",
      "--- 35.54270648956299 seconds ---\n",
      "Epoch : 145\n",
      "learning_rate: 0.000003360\n",
      "train_loss: 0.086993, valid_loss: 0.067014\n",
      "train_f1: 0.882781, valid_f1: 0.914603\n",
      "--- 35.40048336982727 seconds ---\n",
      "Epoch : 146\n",
      "learning_rate: 0.000002148\n",
      "train_loss: 0.087298, valid_loss: 0.067039\n",
      "train_f1: 0.883017, valid_f1: 0.914592\n",
      "--- 35.39422416687012 seconds ---\n",
      "Epoch : 147\n",
      "learning_rate: 0.000001205\n",
      "train_loss: 0.086883, valid_loss: 0.067033\n",
      "train_f1: 0.883187, valid_f1: 0.914593\n",
      "--- 35.59173917770386 seconds ---\n",
      "Epoch : 148\n",
      "learning_rate: 0.000000533\n",
      "train_loss: 0.087220, valid_loss: 0.067045\n",
      "train_f1: 0.882681, valid_f1: 0.914558\n",
      "--- 35.44350838661194 seconds ---\n",
      "Epoch : 149\n",
      "learning_rate: 0.000000131\n",
      "train_loss: 0.087012, valid_loss: 0.067045\n",
      "train_f1: 0.882829, valid_f1: 0.914546\n",
      "--- 35.43709468841553 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "    \n",
    "for index, (train_index, val_index ) in enumerate(new_splits[0:], start=0):\n",
    "    print(\"Fold : {}\".format(index))\n",
    "    \n",
    "    batchsize = 16\n",
    "    train_dataset = IonDataset(trainval[train_index],  trainval_y[train_index], flip=False, noise_level=0.0, class_split=0.0)\n",
    "    train_dataloader = DataLoader(train_dataset, batchsize, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    valid_dataset = IonDataset(trainval[val_index],  trainval_y[val_index], flip=False)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batchsize, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    test_dataset = IonDataset(test,  test_y, flip=False, noise_level=0.0, class_split=0.0)\n",
    "    test_dataloader = DataLoader(test_dataset, batchsize, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    test_preds_iter = np.zeros((2000000, 11))\n",
    "    it = 0\n",
    "    for it in range(1):\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        model=Seq2SeqRnn(input_size=trainval.shape[1], seq_len=4000, hidden_size=64, output_size=11, num_layers=2, hidden_layers=[64,64,64],\n",
    "                         bidirectional=True).to(device)\n",
    "    \n",
    "        no_of_epochs = 150\n",
    "        early_stopping = EarlyStopping(patience=20, is_maximize=True, checkpoint_path=\"./models/gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index, it))\n",
    "        criterion = L.FocalLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, max_lr=0.001, epochs=no_of_epochs,\n",
    "                                                steps_per_epoch=len(train_dataloader))\n",
    "        avg_train_losses, avg_valid_losses = [], [] \n",
    "    \n",
    "    \n",
    "        for epoch in range(no_of_epochs):\n",
    "            start_time = time.time()\n",
    "    \n",
    "            print(\"Epoch : {}\".format(epoch))\n",
    "            print( \"learning_rate: {:0.9f}\".format(schedular.get_lr()[0]))\n",
    "            train_losses, valid_losses = [], []\n",
    "    \n",
    "            model.train() # prep model for training\n",
    "            train_preds, train_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "    \n",
    "            for x, y in train_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(x[:, :trainval.shape[1], :])\n",
    "    \n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                y_ = y.view(-1)\n",
    "    \n",
    "                loss = criterion(predictions_, y_)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                schedular.step()\n",
    "                # record training lossa\n",
    "                train_losses.append(loss.item())\n",
    "    \n",
    "                train_true = torch.cat([train_true, y_], 0)\n",
    "                train_preds = torch.cat([train_preds, predictions_], 0)\n",
    "\n",
    "            model.eval() # prep model for evaluation\n",
    "            val_preds, val_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_dataloader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "    \n",
    "                    predictions = model(x[:,:trainval.shape[1],:])\n",
    "                    predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                    y_ = y.view(-1)\n",
    "    \n",
    "                    loss = criterion(predictions_, y_)\n",
    "                    valid_losses.append(loss.item())\n",
    "        \n",
    "                    val_true = torch.cat([val_true, y_], 0)\n",
    "                    val_preds = torch.cat([val_preds, predictions_], 0)\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            train_loss = np.average(train_losses)\n",
    "            valid_loss = np.average(valid_losses)\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "            \n",
    "            print( \"train_loss: {:0.6f}, valid_loss: {:0.6f}\".format(train_loss, valid_loss))\n",
    "\n",
    "            train_score = f1_score(train_true.cpu().detach().numpy(), train_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "    \n",
    "            val_score = f1_score(val_true.cpu().detach().numpy(), val_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "            print( \"train_f1: {:0.6f}, valid_f1: {:0.6f}\".format(train_score, val_score))\n",
    "    \n",
    "            if early_stopping(val_score, model):\n",
    "                print(\"Early Stopping...\")\n",
    "                print(\"Best Val Score: {:0.6f}\".format(early_stopping.best_score))\n",
    "                break\n",
    "    \n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        model.load_state_dict(torch.load(\"./models/gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index, it)))\n",
    "        with torch.no_grad():\n",
    "            pred_list = []\n",
    "            for x, y in test_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                predictions = model(x[:,:trainval.shape[1],:])\n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "\n",
    "                pred_list.append(F.softmax(predictions_, dim=1).cpu().numpy())\n",
    "            test_preds = np.vstack(pred_list)\n",
    "       \n",
    "        test_preds_iter += test_preds\n",
    "        test_preds_all += test_preds\n",
    "        if not os.path.exists(\"./predictions/test\"):\n",
    "            os.makedirs(\"./predictions/test\")\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_iter_{}_raw.npy'.format(index, it), arr=test_preds_iter)\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_raw.npy'.format(index), arr=test_preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_all = test_preds_all/np.sum(test_preds_all, axis=1)[:, None]\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str),\n",
    "                                'open_channels': np.argmax(test_preds_all, axis=1)})\n",
    "test_pred_frame.to_csv(\"./gru_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
