{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import click\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from IPython.core.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings('ignore')\n",
    "raw_data_path = os.path.join(\"..\", \"..\", \"data\", \"raw\")\n",
    "processed_data_path = os.path.join(\"..\", \"..\", \"data\", \"processed\")\n",
    "external_data_path = os.path.join(\"..\", \"..\", \"data\", \"external\")\n",
    "\n",
    "\n",
    "def paras(post):\n",
    "    paras_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"p\", \"li\"]\n",
    "    try:\n",
    "        soup = bs4.BeautifulSoup(post, \"lxml\")\n",
    "        for element in soup.find_all(paras_tags):\n",
    "            yield element.text\n",
    "        soup.decompose()\n",
    "    except:\n",
    "        logging.info(f\"paras soup exception on text: {post}.\")\n",
    "        yield \"\"\n",
    "\n",
    "\n",
    "def sents(post):\n",
    "    for para in paras(post):\n",
    "        for sentence in sent_tokenize(para):\n",
    "            yield sentence\n",
    "\n",
    "\n",
    "def load_stop_words():\n",
    "    with open(os.path.join(external_data_path, 'russian_stop_words.txt'), 'r') as handle:\n",
    "        stop_words_ru = [line.rstrip('\\n') for line in handle]\n",
    "    with open(os.path.join(external_data_path, 'english_stop_words.txt'), 'r') as handle:\n",
    "        stop_words_en = [line.rstrip('\\n') for line in handle]\n",
    "    return set(stop_words_ru + stop_words_en)\n",
    "\n",
    "\n",
    "def lemmatize(text, morphological_analyzer, stemmer, stop_words):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    lemmatizing_paras = []\n",
    "    for para in paras(text):\n",
    "        lemmatizing_sents = []\n",
    "        for sentence in sents(para):\n",
    "            lemmatizing_words = []\n",
    "            for token_analize in morphological_analyzer.analyze(sentence):\n",
    "                if \"analysis\" in token_analize:\n",
    "                    if token_analize[\"text\"] in stop_words:\n",
    "                        continue\n",
    "                    if token_analize[\"analysis\"]:\n",
    "                        find = re.compile(\"([^,=]+)\")\n",
    "                        lexem = token_analize[\"analysis\"][0][\"lex\"]\n",
    "                        if lexem in stop_words:\n",
    "                            continue\n",
    "                        grammemes = token_analize[\"analysis\"][0][\"gr\"]\n",
    "                        grammeme = re.search(find, grammemes).group(0)\n",
    "                        lemmatizing_words.append(f\"{lexem}_{grammeme}\")\n",
    "                    else:\n",
    "                        lexem = stemmer.stem(token_analize[\"text\"])\n",
    "                        if lexem in stop_words:\n",
    "                            continue\n",
    "                        lemmatizing_words.append(lexem)\n",
    "            if len(lemmatizing_words):\n",
    "                lemmatizing_sents.append(lemmatizing_words)\n",
    "        print(len(lemmatizing_sents))\n",
    "        if len(lemmatizing_sents):\n",
    "            lemmatizing_paras.append(lemmatizing_sents)\n",
    "    return lemmatizing_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-29 01:20:04,575 : INFO : Create MongoDB connection...\n",
      "2020-03-29 01:20:05,488 : INFO : Collection has 518456 documents without preprocessing 'body'.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Create MongoDB connection...\")\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.publicru_test\n",
    "collection = db.documents_collection\n",
    "\n",
    "logging.info(\n",
    "    f\"Collection has {collection.count_documents({'pt_body': None})} documents without preprocessing 'body'.\")\n",
    "\n",
    "morphological_analyzer = Mystem()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = load_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16\n",
    "# result = collection.find({}).skip(0 if n == 0 else (n - 1)).limit(1)\n",
    "result = collection.find({}).skip(n).limit(1)\n",
    "document = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "5\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "t_body = lemmatize(document[\"body\"], morphological_analyzer, stemmer, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<body><p>Мнения спикеров. Итоги</p>\\n<p>Ширлин Лим, генеральный менеджер отеля Radisson Sonya*, Санкт Петербург, - амбассадор программы «Женщины-лидеры» (Women in Leadership*) компании Carlson Rezidor*</p>\\n<p>В современном бизнес-сообществе уже давно нет разделений на мужчин и женщин: все в равной степени являются партнерами. Подобную концепцию мы постоянно слышим и читаем в известных журналах, посвященных бизнесу. Однако, согласно исследованию портала hh.ru (http://spb.hh.ru/article/17038), каждая пятая женщина в России полагает, что гендерные стереотипы так или иначе повлияли на их карьерный рост.</p>\\n<p>По словам Татьяны Старковой, технического специалиста компании, занимающейся разработкой программного обеспечения для автоматизации грузовых авиаперевозок, гендерные предубеждения - это повседневная сторона ее работы. Она отмечает, что среди основной массы клиентов технические специалисты мужского пола пользуются большим доверием, чем женщины. Она отмечает, что женщины тем не менее не должны быть излишне скромными ним стоит чаще рассказывать о своих достижениях, зачастую они сами излишне сомневаются в себе, не говорят достаточно громко, чтобы быть услышанными.</p>\\n<p>Многие международные компании уже начали задумываться и принимать активные меры по поддержке женщин. В компании Carlson Rezidor Hotel Group* реализуется проект «Женщины-лидеры» (Women in Leadership), направленный на подчеркивание гендерного разнообразия и вовлечение женщин в диалог. Одним из основных инструментов проекта является гибкий рабочий график: женщина один или даже два раза в неделю может работать из дома. Проект «Женщины-лидеры» нацелен не только на преобразование гендерного баланса в компании, но и создан как пример для других. Задачами подобных проектов должны стать ведение диалогов между людьми, создание почвы для изменения культуры и, конечно, поддержка всех женщин. Их призвание - поставить под сомнение существующее мышление и увеличить количество женщин на руководящих позициях, пока женщина-руководитель не станет нормой.</p>\\n<p>***</p>\\n<p>Татьяна Круглова, коммерческий директор, Clarins Group Россия</p>\\n<p>В социуме всегда существовали стереотипы в отношении мужчин и женщин, которые акцентируются на различиях, а не на сходствах. Ученые всего мира сходятся во мнении, что гендерная и ролевая идентификации влияют на положение в современном обществе, личную жизнь и профессиональную деятельность, самооценку и отношения с окружающими людьми.</p>\\n<p>С начала XXI века произошли огромные изменения в жизни общества. Одним из них является усиление роли женщины в различных сферах общественной жизни - экономике, политике, науке, искусстве и, конечно же, бизнесе. Именно поэтому вопрос взаимоотношения полов стал неотъемлемой частью повседневности. Исторически принято считать, что между мужчиной и женщиной лежит пропасть различий потому, что мы являемся противоположностями. Но, на мой взгляд, не существует мужского или женского стиля управления. Если человек является профессионалом в своем деле, постоянно развивается, следит за тенденциями рынка, активностью конкурентов и не прекращает учиться, то половая принадлежность не является ключевым фактором успеха.</p>\\n<p>Соглашусь, что большинство мужчин более амбициозны и быстрее женщин получают руководящие должности в силу того, что меньше сомневаются в себе, тогда как женщина зачастую отдает предпочтение семье и детям, не реализуя свои возможности и карьерные амбиции. У меня есть стойкое ощущение, что женщина могла бы добиться намного большего, если бы она только захотела. За последние 1015 лет ситуация в нашей стране сильно изменилась: женщины управляют крупными предприятиями, открывают и руководят локальными офисами международных компаний, создают собственный бизнес, уверенно чувствуют себя в политике, строительстве, металлургии - сферах, ранее считавшихся мужскими. При этом я абсолютно убеждена, что чем больше социальных ролей женщине удается совмещать, тем успешнее, продуктивнее и счастливее она себя чувствует. Во всем важно найти баланс, особенно женщине в современном мире, и сильное плечо любимого мужчины рядом - это всегда уверенность, гармония и счастье, на какие бы вершины успеха мы ни забирались.</p>\\n<p>ПО ВОПРОСАМ УЧАСТИЯ И ПАРТНЕРСТВА:</p>\\n<p>+7 (495) 363-03-14</p>\\n<p>e.abramova@rbc.ru</p>\\n<p>(*) Рэдиссон Соня; женщины-лидеры; Карлсон Резидор, Карлсон Резидор Отель Групп</p>\\n<p>Реклама. 18+</p>\\n</body>'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['мнение_S', 'спикер_S'], ['итог_S']],\n",
       " [['ширлин_S',\n",
       "   'лим_S',\n",
       "   'генеральный_A',\n",
       "   'менеджер_S',\n",
       "   'отель_S',\n",
       "   'radisson',\n",
       "   'sonya',\n",
       "   'санкт_COM',\n",
       "   'петербург_S',\n",
       "   'амбассадор_S',\n",
       "   'программа_S',\n",
       "   'женщина_S',\n",
       "   'лидер_S',\n",
       "   'women',\n",
       "   'leadership',\n",
       "   'компания_S',\n",
       "   'carlson',\n",
       "   'rezidor']],\n",
       " [['современный_A',\n",
       "   'бизнес_S',\n",
       "   'сообщество_S',\n",
       "   'разделение_S',\n",
       "   'мужчина_S',\n",
       "   'женщина_S',\n",
       "   'равный_A',\n",
       "   'степень_S',\n",
       "   'являться_V',\n",
       "   'партнер_S'],\n",
       "  ['подобный_A',\n",
       "   'концепция_S',\n",
       "   'постоянно_ADV',\n",
       "   'слышать_V',\n",
       "   'читать_V',\n",
       "   'известный_A',\n",
       "   'журнал_S',\n",
       "   'посвящать_V',\n",
       "   'бизнес_S'],\n",
       "  ['согласно_PR',\n",
       "   'исследование_S',\n",
       "   'портал_S',\n",
       "   'hh',\n",
       "   'ru',\n",
       "   'женщина_S',\n",
       "   'россия_S',\n",
       "   'полагать_V',\n",
       "   'гендерный_A',\n",
       "   'стереотип_S',\n",
       "   'иначе_CONJ',\n",
       "   'повлиять_V',\n",
       "   'карьерный_A',\n",
       "   'рост_S']],\n",
       " [['слово_S',\n",
       "   'татьяна_S',\n",
       "   'старкова_S',\n",
       "   'технический_A',\n",
       "   'специалист_S',\n",
       "   'компания_S',\n",
       "   'заниматься_V',\n",
       "   'разработка_S',\n",
       "   'программный_A',\n",
       "   'обеспечение_S',\n",
       "   'автоматизация_S',\n",
       "   'грузовой_A',\n",
       "   'авиаперевозка_S',\n",
       "   'гендерный_A',\n",
       "   'предубеждение_S',\n",
       "   'повседневный_A',\n",
       "   'сторона_S',\n",
       "   'работа_S'],\n",
       "  ['отмечать_V',\n",
       "   'среди_PR',\n",
       "   'основной_A',\n",
       "   'масса_S',\n",
       "   'клиент_S',\n",
       "   'технический_A',\n",
       "   'специалист_S',\n",
       "   'мужской_A',\n",
       "   'пол_S',\n",
       "   'пользоваться_V',\n",
       "   'больший_A',\n",
       "   'доверие_S',\n",
       "   'женщина_S'],\n",
       "  ['отмечать_V',\n",
       "   'женщина_S',\n",
       "   'излишне_ADV',\n",
       "   'скромный_A',\n",
       "   'стоять_V',\n",
       "   'рассказывать_V',\n",
       "   'достижение_S',\n",
       "   'зачастую_ADV',\n",
       "   'излишне_ADV',\n",
       "   'сомневаться_V',\n",
       "   'говорить_V',\n",
       "   'достаточно_ADV',\n",
       "   'громко_ADV',\n",
       "   'услышать_V']],\n",
       " [['многий_APRO',\n",
       "   'международный_A',\n",
       "   'компания_S',\n",
       "   'начинать_V',\n",
       "   'задумываться_V',\n",
       "   'принимать_V',\n",
       "   'активный_A',\n",
       "   'мера_S',\n",
       "   'поддержка_S',\n",
       "   'женщина_S'],\n",
       "  ['компания_S',\n",
       "   'carlson',\n",
       "   'rezidor',\n",
       "   'hotel',\n",
       "   'group',\n",
       "   'реализоваться_V',\n",
       "   'проект_S',\n",
       "   'женщина_S',\n",
       "   'лидер_S',\n",
       "   'women',\n",
       "   'leadership',\n",
       "   'направлять_V',\n",
       "   'подчеркивание_S',\n",
       "   'гендерный_A',\n",
       "   'разнообразие_S',\n",
       "   'вовлечение_S',\n",
       "   'женщина_S',\n",
       "   'диалог_S'],\n",
       "  ['основной_A',\n",
       "   'инструмент_S',\n",
       "   'проект_S',\n",
       "   'являться_V',\n",
       "   'гибкий_A',\n",
       "   'рабочий_A',\n",
       "   'график_S',\n",
       "   'женщина_S',\n",
       "   'неделя_S',\n",
       "   'работать_V',\n",
       "   'дом_S'],\n",
       "  ['проект_S',\n",
       "   'женщина_S',\n",
       "   'лидер_S',\n",
       "   'нацеливать_V',\n",
       "   'преобразование_S',\n",
       "   'гендерный_A',\n",
       "   'баланс_S',\n",
       "   'компания_S',\n",
       "   'создавать_V',\n",
       "   'пример_S'],\n",
       "  ['задача_S',\n",
       "   'подобный_A',\n",
       "   'проект_S',\n",
       "   'становиться_V',\n",
       "   'ведение_S',\n",
       "   'диалог_S',\n",
       "   'создание_S',\n",
       "   'почва_S',\n",
       "   'изменение_S',\n",
       "   'культура_S',\n",
       "   'поддержка_S',\n",
       "   'женщина_S'],\n",
       "  ['призвание_S',\n",
       "   'поставлять_V',\n",
       "   'сомнение_S',\n",
       "   'существующий_A',\n",
       "   'мышление_S',\n",
       "   'увеличивать_V',\n",
       "   'количество_S',\n",
       "   'женщина_S',\n",
       "   'руководящий_A',\n",
       "   'позиция_S',\n",
       "   'женщина_S',\n",
       "   'руководитель_S',\n",
       "   'становиться_V',\n",
       "   'норма_S']],\n",
       " [['татьяна_S',\n",
       "   'круглов_S',\n",
       "   'коммерческий_A',\n",
       "   'директор_S',\n",
       "   'clarin',\n",
       "   'group',\n",
       "   'россия_S']],\n",
       " [['социум_S',\n",
       "   'существовать_V',\n",
       "   'стереотип_S',\n",
       "   'отношение_S',\n",
       "   'мужчина_S',\n",
       "   'женщина_S',\n",
       "   'акцентироваться_V',\n",
       "   'различие_S',\n",
       "   'сходство_S'],\n",
       "  ['ученый_S',\n",
       "   'сходиться_V',\n",
       "   'мнение_S',\n",
       "   'гендерный_A',\n",
       "   'ролевой_A',\n",
       "   'идентификация_S',\n",
       "   'влиять_V',\n",
       "   'положение_S',\n",
       "   'современный_A',\n",
       "   'общество_S',\n",
       "   'личный_A',\n",
       "   'профессиональный_A',\n",
       "   'деятельность_S',\n",
       "   'самооценка_S',\n",
       "   'отношение_S',\n",
       "   'окружающий_A']],\n",
       " [['xxi', 'век_S', 'происходить_V', 'огромный_A', 'изменение_S', 'общество_S'],\n",
       "  ['являться_V',\n",
       "   'усиление_S',\n",
       "   'роль_S',\n",
       "   'женщина_S',\n",
       "   'различный_A',\n",
       "   'сфера_S',\n",
       "   'общественный_A',\n",
       "   'экономика_S',\n",
       "   'политика_S',\n",
       "   'наука_S',\n",
       "   'искусство_S',\n",
       "   'бизнес_S'],\n",
       "  ['поэтому_ADVPRO',\n",
       "   'вопрос_S',\n",
       "   'взаимоотношение_S',\n",
       "   'пол_S',\n",
       "   'неотъемлемый_A',\n",
       "   'часть_S',\n",
       "   'повседневность_S'],\n",
       "  ['исторически_ADV',\n",
       "   'принимать_V',\n",
       "   'считать_V',\n",
       "   'мужчина_S',\n",
       "   'женщина_S',\n",
       "   'лежать_V',\n",
       "   'пропадать_V',\n",
       "   'различие_S',\n",
       "   'являться_V',\n",
       "   'противоположность_S'],\n",
       "  ['взгляд_S',\n",
       "   'существовать_V',\n",
       "   'мужской_A',\n",
       "   'женский_A',\n",
       "   'стиль_S',\n",
       "   'управление_S'],\n",
       "  ['являться_V',\n",
       "   'профессионал_S',\n",
       "   'свой_APRO',\n",
       "   'дело_S',\n",
       "   'постоянно_ADV',\n",
       "   'развиваться_V',\n",
       "   'следить_V',\n",
       "   'тенденция_S',\n",
       "   'рынок_S',\n",
       "   'активность_S',\n",
       "   'конкурент_S',\n",
       "   'прекращать_V',\n",
       "   'учиться_V',\n",
       "   'половой_A',\n",
       "   'принадлежность_S',\n",
       "   'являться_V',\n",
       "   'ключевой_A',\n",
       "   'фактор_S',\n",
       "   'успех_S']],\n",
       " [['соглашаться_V',\n",
       "   'большинство_S',\n",
       "   'мужчина_S',\n",
       "   'амбициозный_A',\n",
       "   'быстро_ADV',\n",
       "   'женщина_S',\n",
       "   'получать_V',\n",
       "   'руководящий_A',\n",
       "   'должность_S',\n",
       "   'сила_S',\n",
       "   'сомневаться_V',\n",
       "   'женщина_S',\n",
       "   'зачастую_ADV',\n",
       "   'отдавать_V',\n",
       "   'предпочтение_S',\n",
       "   'семья_S',\n",
       "   'ребенок_S',\n",
       "   'реализовать_V',\n",
       "   'возможность_S',\n",
       "   'карьерный_A',\n",
       "   'амбиция_S'],\n",
       "  ['стойкий_A',\n",
       "   'ощущение_S',\n",
       "   'женщина_S',\n",
       "   'добиваться_V',\n",
       "   'намного_ADV',\n",
       "   'больший_A',\n",
       "   'захотеть_V'],\n",
       "  ['последний_A',\n",
       "   'ситуация_S',\n",
       "   'страна_S',\n",
       "   'сильно_ADV',\n",
       "   'изменяться_V',\n",
       "   'женщина_S',\n",
       "   'управлять_V',\n",
       "   'крупный_A',\n",
       "   'предприятие_S',\n",
       "   'открывать_V',\n",
       "   'руководить_V',\n",
       "   'локальный_A',\n",
       "   'офис_S',\n",
       "   'международный_A',\n",
       "   'компания_S',\n",
       "   'создавать_V',\n",
       "   'собственный_A',\n",
       "   'бизнес_S',\n",
       "   'уверенно_ADV',\n",
       "   'чувствовать_V',\n",
       "   'политика_S',\n",
       "   'строительство_S',\n",
       "   'металлургия_S',\n",
       "   'сфера_S',\n",
       "   'ранее_ADV',\n",
       "   'считаться_V',\n",
       "   'мужской_A'],\n",
       "  ['абсолютно_ADV',\n",
       "   'убеждать_V',\n",
       "   'социальный_A',\n",
       "   'роль_S',\n",
       "   'женщина_S',\n",
       "   'удаваться_V',\n",
       "   'совмещать_V',\n",
       "   'успешно_ADV',\n",
       "   'продуктивно_ADV',\n",
       "   'счастливо_ADV',\n",
       "   'чувствовать_V'],\n",
       "  ['важно_ADV',\n",
       "   'находить_V',\n",
       "   'баланс_S',\n",
       "   'женщина_S',\n",
       "   'современный_A',\n",
       "   'мир_S',\n",
       "   'сильный_A',\n",
       "   'плечо_S',\n",
       "   'любимый_S',\n",
       "   'мужчина_S',\n",
       "   'уверенность_S',\n",
       "   'гармония_S',\n",
       "   'счастие_S',\n",
       "   'вершина_S',\n",
       "   'успех_S',\n",
       "   'забираться_V']],\n",
       " [['вопрос_S', 'участие_S', 'партнерство_S']],\n",
       " [['abramova', 'rbc', 'ru']],\n",
       " [['рэдиссон_S',\n",
       "   'соня_S',\n",
       "   'женщина_S',\n",
       "   'лидер_S',\n",
       "   'карлсон_S',\n",
       "   'резидор_S',\n",
       "   'карлсон_S',\n",
       "   'резидор_S',\n",
       "   'отель_S',\n",
       "   'группа_S']],\n",
       " [['реклама_S']]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(document):\n",
    "    collection.update_one({\"doc_id\": document[\"doc_id\"]}, {\"$set\": {\n",
    "        \"t_title\": lemmatize(document[\"title\"], morphological_analyzer, stemmer, stop_words),\n",
    "        \"t_body\": lemmatize(document[\"body\"], morphological_analyzer, stemmer, stop_words),\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-28:\n",
      "2020-03-28 22:56:13,815 : INFO : paras soup exception on text: Новости за рубежом: цветные металлы | Спрос на медь будет расширяться, но не везде.\n",
      "2020-03-28 22:56:13,814 : INFO : paras soup exception on text: У нас другой маневр - все внимание сфокусировано на перспективных рынках, «голубых океанах», которые только формируются и размер которых в ближайшие 20 лет превысит 100 миллиардов долларов. На их покорение у нас такие же шансы, как и у других стран. Успех будет зависеть от степени концентрации усилий бизнеса, государства и общества на строительстве в России экономики знаний..\n",
      "2020-03-28 22:56:13,815 : INFO : paras soup exception on text: Разрешают голосовать гражданам, проживающим за пределами страны, 111 государств, в частности Германия, Канада, США, Франция, Сербия, Италия, Белоруссия. А 64 государства разрешают участвовать в выборах даже тем, кто не проживает, а просто находится за пределами страны в день выборов - в отпуске, туристической поездке, по студенческому обмену. Такие правила действуют в Австрии, Дании, Эстонии, Люксембурге. Личный состав Вооруженных сил, находящийся за границей, допускают к выборам в 41 стране - Латвии, Украине, Анголе, США, Израиле и др., а дипломатический персонал - в 52 странах..\n",
      "Process ForkPoolWorker-29:\n",
      "2020-03-28 22:56:13,814 : INFO : paras soup exception on text: государственный контроль; надзор; муниципальный контроль; индикаторы риска; обязательные требования; внеплановые проверки; риск-ориентированный подход; управление рисками.\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-10:\n",
      "Exception ignored in: <generator object paras at 0x7f274144a2d0>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <generator object paras at 0x7f27411aadd0>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "2020-03-28 22:56:13,815 : INFO : paras soup exception on text: Судебный спор между ООО «Эппл Рус» и ФТС возник из-за того, что и таможенные органы по-разному классифицировали «умные» часы Apple Watch..\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: generator ignored GeneratorExit\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-22:\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "RuntimeError: generator ignored GeneratorExit\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Exception ignored in: <generator object paras at 0x7f274105dcd0>\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "2020-03-28 22:56:13,856 : INFO : paras soup exception on text: <body><p><b>Член ЦИК РФ, чрезвычайный и полномочный посол</b></p>\n",
      "<p><b>Не только вся Россия - весь «русский мир» тоже будет голосовать на выборах президента в марте 2018 года. Речь идет о российских гражданах, постоянно проживающих за рубежом. Наше законодательство дает им возможность голосовать на выборах главы государства - кстати, такая возможность есть далеко не у всех жителей западноевропейских государств. Россия тут выступает как обладатель одной из лучших мировых практик. Но пользуются такой возможностью далеко не все. Поэтому вопрос, как повысить явку среди россиян, постоянно живущих за границей, остается отк рытым.</b></p>\n",
      "<p>Для начала обосную тезис, почему именно у нас одна из лучших практик в мире. Далеко не все знают, что почти треть государств мира не разрешает своим гражданам, находящимся за границей, голосовать на национальных выборах. Это 62 страны, среди них Чили, Греция, Мальта, Пакистан, Нигерия.</p>\n",
      "<p>Разрешают голосовать гражданам, проживающим за пределами страны, 111 государств, в частности Германия, Канада, США, Франция, Сербия, Италия, Белоруссия. А 64 государства разрешают участвовать в выборах даже тем, кто не проживает, а просто находится за пределами страны в день выборов - в отпуске, туристической поездке, по студенческому обмену. Такие правила действуют в Австрии, Дании, Эстонии, Люксембурге. Личный состав Вооруженных сил, находящийся за границей, допускают к выборам в 41 стране - Латвии, Украине, Анголе, США, Израиле и др., а дипломатический персонал - в 52 странах.</p>\n",
      "<p>Потенциальных российских избирателей за границей около 5 млн человек - такую цифру можно вывести, принимая во внимание анализ ООН, Всемирного банка и других международных структур. Но на консульском учете, по данным МИД РФ, сегодня состоит 1 917 356 человек. Конечно, в день выборов это количество может меняться в ту или иную сторону. Однако порядок цифр очевиден: сопоставимой численностью избирателей могут похвастаться лишь некоторые субъекты, такие, например, как Ставропольский и Красноярский края, Новосибирская область.</p>\n",
      "<p>А что на этом грандиозном, но размытом территориально по всему миру участке творится с явкой? Одна цифра: на выборах в сентябре 2016 года явка по зарубежным участкам составила 11,43% от 1 887 740 граждан, зарегистрированных по месту пребывания консульствами. А это более чем в четыре раза меньше показателя явки на территории России - 47,88%. Лидерами по участию в голосовании стали Молдавия, Абхазия и Латвия. Минимальная явка зарегистрирована на Украине, в Германии и Узбекистане. При этом все условия для качественных выборов за рубежом были созданы, для этого большую работу провели ЦИК, Минобороны, МИД, Россотрудничество, Ростуризм. Какие еще меры по повышению явки можно предложить? Назовем несколько реальных шагов.</p>\n",
      "<p>Во-первых, усиление пропагандистской, разъяснительной работы. Это задача и для российских загранучреждений, и Всемирного координационного совета российских соотечественников, и, конечно, представителей СМИ.</p>\n",
      "<p>Во-вторых, совершенствование статуса и структуры участковых (УИКи) и территориальных (ТИКи) избиркомов. Тут могут потребоваться законодательные поправки об их составе, функциях, расширение финансово-материальной поддержки. Все эти аспекты ЦИК активно обсуждает сегодня в переписке с гражданами России, проживающими в США, Израиле, странах Прибалтики, Финляндии.</p>\n",
      "<p>В-третьих, надо вообще пересмотреть принципы работы российских партий и общественных объединений с электоральным потенциалом РФ за рубежом. Это очень перспективное направление. Трудно переоценить его вклад в имидж страны, преодоление всякого рода антироссийских подходов, русофобии.</p>\n",
      "<p>Наконец, очень полезным может оказаться взаимодействие с международными наблюдателями. На сентябрьских выборах в Госдуму их число достигло 774, наблюдатели представляли 57 государств и 11 международных организаций. А в марте 2018 года их, скорее всего, будет еще больше, учитывая многоплановый интерес международного сообщества к выборам главы российского государства. Это закономерно. Следовательно, мы должны готовиться и к пристальному вниманию международных наблюдателей к голосованию за пределами территории РФ.</p>\n",
      "<p>Наши соотечественники за рубежом - люди думающие, инициативные, со своими взглядами и суждениями, в том числе и критическими. Для них характерны особые политические пристрастия: в сентябре 2016 года «Единая Россия» и «Яблоко» получили за рубежом больше процентов голосов, чем внутри страны. Участки должны стать для этих людей настоящей «зоной притяжения», пусть небольшим, но кирпичиком построения идентичности. Чем более громко и уверенно заявят они о своем выборе в марте 2018 года, тем с большей уверенностью мы сможем сказать, что голосование было честным и легитимным.</p>\n",
      "<p>***</p>\n",
      "<p>\"НАДО ПЕРЕСМОТ­РЕТЬ ПРИНЦИПЫ РАБОТЫ РОССИЙСКИХ ПАРТИЙ И ОБЩЕСТВЕННЫХ ОБЪЕДИНЕНИЙ С ЭЛЕКТОРАЛЬНЫМ ПОТЕНЦИАЛОМ РФ ЗА РУБЕЖОМ. ЭТО ПЕРСПЕКТИВНОЕ НАПРАВЛЕНИЕ. ТРУДНО ПЕРЕОЦЕНИТЬ ЕГО ВКЛАД В ИМИДЖ СТРАНЫ, ПРЕОДОЛЕНИЕ АНТИРОССИЙСКИХ ПОДХОДОВ, РУСОФОБИИ</p>\n",
      "<p><img alt=\"Василий Лихачев\" src=\"134817/1.jpg\" title=\"Василий Лихачев\"/></p>\n",
      "</body>.\n",
      "  File \"/home/science/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(cpu_count()) as p:\n",
    "    print(p.map(run, collection.find({\"pt_body\": {\"$exists\": False}}, no_cursor_timeout=True).limit(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588456"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({\"pt_body\": {\"$exists\": False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457.7988154888153\n",
      "CPU times: user 4min 45s, sys: 29.9 s, total: 5min 15s\n",
      "Wall time: 7min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "documents = [{\"a number\": i} for i in range(1000000)]\n",
    "\n",
    "time1s = time.time()\n",
    "client = MongoClient()\n",
    "db = client.mydb\n",
    "col = db.mycol\n",
    "for doc in documents:\n",
    "    col.insert_one(doc)\n",
    "\n",
    "print(time.time()-time1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 512 ms, sys: 417 ms, total: 930 ms\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "documents = [{\"number\": i} for i in range(1000000)]\n",
    "\n",
    "def insert_doc(chunk):\n",
    "    client = MongoClient()\n",
    "    db = client.mydb\n",
    "    col = db.mycol\n",
    "    col.insert_many(chunk)\n",
    "\n",
    "chunk_size = 10000\n",
    "\n",
    "def chunks(sequence):\n",
    "    # Chunks of 1000 documents at a time.\n",
    "    for j in range(0, len(sequence), chunk_size):\n",
    "        yield sequence[j:j + chunk_size]\n",
    "\n",
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "pool.map(insert_doc, chunks(documents))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sequence = collection.count_documents({\"pt_body\": {\"$exists\": False}})\n",
    "chunk_size = 10000\n",
    "\n",
    "def chunks(sequence):\n",
    "    for j in range(0, len_sequence, chunk_size):\n",
    "        yield sequence[j:j + chunk_size]\n",
    "\n",
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "pool.map(insert_doc, chunks(collection.find({\"pt_body\": {\"$exists\": False}}, no_cursor_timeout=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 1.45 s, total: 30.7 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.publicru_test\n",
    "collection = db.documents_collection\n",
    "\n",
    "documents = []\n",
    "for document in collection.find({\"pt_body\": {\"$exists\": False}}, no_cursor_timeout=True).limit(1000):\n",
    "    document[\"t_title\"] = lemmatize(document[\"title\"], morphological_analyzer, stemmer, stop_words),\n",
    "    document[\"t_body\"] = lemmatize(document[\"body\"], morphological_analyzer, stemmer, stop_words),\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.442199999999998"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({}) / 1000 * 70 / 60 / 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import click\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from IPython.core.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings('ignore')\n",
    "raw_data_path = os.path.join(\"..\", \"..\", \"data\", \"raw\")\n",
    "processed_data_path = os.path.join(\"..\", \"..\", \"data\", \"processed\")\n",
    "external_data_path = os.path.join(\"..\", \"..\", \"data\", \"external\")\n",
    "\n",
    "\n",
    "def paras(post):\n",
    "    paras_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"p\", \"li\"]\n",
    "    try:\n",
    "        soup = bs4.BeautifulSoup(post, \"lxml\")\n",
    "        for element in soup.find_all(paras_tags):\n",
    "            yield element.text\n",
    "        soup.decompose()\n",
    "    except:\n",
    "        logging.info(f\"paras soup exception on text: {post}.\")\n",
    "        yield \"\"\n",
    "\n",
    "\n",
    "def sents(post):\n",
    "    for para in paras(post):\n",
    "        for sentence in sent_tokenize(para):\n",
    "            yield sentence\n",
    "\n",
    "\n",
    "def load_stop_words():\n",
    "    with open(os.path.join(external_data_path, 'russian_stop_words.txt'), 'r') as handle:\n",
    "        stop_words_ru = [line.rstrip('\\n') for line in handle]\n",
    "    with open(os.path.join(external_data_path, 'english_stop_words.txt'), 'r') as handle:\n",
    "        stop_words_en = [line.rstrip('\\n') for line in handle]\n",
    "    return set(stop_words_ru + stop_words_en)\n",
    "\n",
    "\n",
    "def lemmatize(text, morphological_analyzer, stemmer, stop_words):\n",
    "    lemmatizing_paras = []\n",
    "    for para in paras(text):\n",
    "        lemmatizing_sents = []\n",
    "        for sentence in sents(para):\n",
    "            lemmatizing_words = []\n",
    "            for token_analize in morphological_analyzer.analyze(sentence):\n",
    "                if \"analysis\" in token_analize:\n",
    "                    if token_analize[\"text\"] in stop_words:\n",
    "                        continue\n",
    "                    if token_analize[\"analysis\"]:\n",
    "                        find = re.compile(\"([^,=]+)\")\n",
    "                        lexem = token_analize[\"analysis\"][0][\"lex\"]\n",
    "                        if lexem in stop_words:\n",
    "                            continue\n",
    "                        grammemes = token_analize[\"analysis\"][0][\"gr\"]\n",
    "                        grammeme = re.search(find, grammemes).group(0)\n",
    "                        lemmatizing_words.append(f\"{lexem}_{grammeme}\")\n",
    "                    else:\n",
    "                        lexem = stemmer.stem(token_analize[\"text\"])\n",
    "                        if lexem in stop_words:\n",
    "                            continue\n",
    "                        lemmatizing_words.append(lexem)\n",
    "            lemmatizing_sents.append(lemmatizing_words)\n",
    "        lemmatizing_paras.append(lemmatizing_sents)\n",
    "    return lemmatizing_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphological_analyzer = Mystem()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = load_stop_words()\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.publicru_test\n",
    "collection = db.documents_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x7f3289887780>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_many({}, { \"$unset\": { \"t_body\": \"\", \"t_title\": \"\", \"pt_body\": \"\", \"pt_title\": \"\" } })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.604802"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({}) / 10000 * 37 / 60 / 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 676 ms, total: 11.7 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for document in documents:\n",
    "    collection.update_one({\"doc_id\": document[\"doc_id\"]}, {\"$set\": {\n",
    "            \"pt_title\": document[\"pt_title\"],\n",
    "            \"pt_body\": document[\"pt_body\"],\n",
    "        }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "morphological_analyzer = Mystem()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = load_stop_words()\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.publicru_test\n",
    "collection = db.documents_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 14.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def lem_doc(document):\n",
    "    document[\"pt_title\"] = lemmatize(document[\"title\"], morphological_analyzer, stemmer, stop_words),\n",
    "    document[\"pt_body\"] = lemmatize(document[\"body\"], morphological_analyzer, stemmer, stop_words),\n",
    "    return document\n",
    "\n",
    "    \n",
    "def update_doc(chunk):\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    db = client.publicru_test\n",
    "    collection = db.documents_collection\n",
    "    for document in chunk:\n",
    "        collection.update_one({\"doc_id\": document[\"doc_id\"]}, {\"$set\": {\n",
    "                \"pt_title\": document[\"pt_title\"],\n",
    "                \"pt_body\": document[\"pt_body\"],\n",
    "            }})\n",
    "\n",
    "        \n",
    "def chunks(sequence):\n",
    "    # Chunks of 1000 documents at a time.\n",
    "    for j in range(0, len(sequence), chunk_size):\n",
    "        yield sequence[j:j + chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 18.5 s, total: 1min 37s\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chunk_size = 1000\n",
    "docs_for_update = 50000  \n",
    "    \n",
    "with mp.Pool(mp.cpu_count()) as p:\n",
    "    documents = p.map(lem_doc, collection.find({\"pt_body\": {\"$exists\": False}}, no_cursor_timeout=True).limit(docs_for_update))\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as p:\n",
    "    p.map(update_doc, chunks(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.15296"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({}) / docs_for_update * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunk_size = 1000\n",
    "docs_for_update = 50000\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as p:\n",
    "    documents = p.map(lem_doc, collection.find({\"pt_body\": {\"$exists\": False}}, no_cursor_timeout=True).limit(docs_for_update))\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as p:\n",
    "    p.map(update_doc, chunks(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f69488142ff456287e7971b76a9bc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38456.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chunk_size = 1000\n",
    "docs_for_update = 50000\n",
    "\n",
    "for i in tqdm(range(round(collection.count_documents({}) / docs_for_update))):\n",
    "    with mp.Pool(mp.cpu_count()) as p:\n",
    "        documents = p.map(lem_doc, collection.find({\"pt_body\": {\"$exists\": False}}, no_cursor_timeout=True).limit(docs_for_update))\n",
    "\n",
    "    with mp.Pool(mp.cpu_count()) as p:\n",
    "        p.map(update_doc, chunks(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38456"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({}) % docs_for_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af6937502814d278cffabd71f2e4995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(round(collection.count_documents({}) / docs_for_update))):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5e7854ebc59124ce04becf39'),\n",
       " 'title': 'Эффект слабого рубля',\n",
       " 'annotation': 'Мы взяли две компании с сопоставимой выручкой и оценили влияние курса рубля на их финансы. Первый участник - это производитель удобрений - «ФосАгро», который большую часть выручки получает от экспорта.',\n",
       " 'body': '<body><p><b>Мы взяли две компании с сопоставимой выручкой и оценили влияние курса рубля на их финансы. Первый участник - это производитель удобрений - «ФосАгро», который большую часть выручки получает от экспорта. Второй участник ориентирован на внутренний рынок - это компания «М.видео», продающая электронику и технику. В качестве начала отчета возьмем 2013 год, когда курс рубля к доллару оставался стабильным и находился в диапазоне 30 - 33,5.</b></p>\\n<p><img alt=\"\" src=\"325/1.jpg\" title=\"\"/></p>\\n</body>',\n",
       " 'authors': nan,\n",
       " 'issue_id': 9,\n",
       " 'edition_id': 1,\n",
       " 'issue_date': '2016-10-01',\n",
       " 'edition_type': 'magazine',\n",
       " 'edition_periodicity': 'monthly',\n",
       " 'edition_description': 'Журнал «РБК» — это аналитические статьи, посвящённые проблемам бизнеса, прогнозы и анализы тенденций российской и мировой экономики, интервью с представителями российской и западной бизнес-элиты, опыт работы и достижения различных компаний. Особенностью журнала является публикация карт бизнеса и бизнес-расследований.',\n",
       " 'edition_name': 'РБК Журнал',\n",
       " 'doc_id': 325,\n",
       " 't_body': [['взять_V',\n",
       "   'компания_S',\n",
       "   'сопоставимый_A',\n",
       "   'выручка_S',\n",
       "   'оценивать_V',\n",
       "   'влияние_S',\n",
       "   'курс_S',\n",
       "   'рубль_S',\n",
       "   'финансы_S'],\n",
       "  ['участник_S',\n",
       "   'производитель_S',\n",
       "   'удобрение_S',\n",
       "   'фосагро_S',\n",
       "   'большой_A',\n",
       "   'часть_S',\n",
       "   'выручка_S',\n",
       "   'получать_V',\n",
       "   'экспорт_S'],\n",
       "  ['участник_S',\n",
       "   'ориентировать_V',\n",
       "   'внутренний_A',\n",
       "   'рынок_S',\n",
       "   'компания_S',\n",
       "   'видео_S',\n",
       "   'продавать_V',\n",
       "   'электроника_S',\n",
       "   'техника_S'],\n",
       "  ['качество_S',\n",
       "   'отчет_S',\n",
       "   'взять_V',\n",
       "   'курс_S',\n",
       "   'рубль_S',\n",
       "   'доллар_S',\n",
       "   'оставаться_V',\n",
       "   'стабильный_A',\n",
       "   'находиться_V',\n",
       "   'диапазон_S']],\n",
       " 't_title': [['эффект_S', 'слабый_A', 'рубль_S']],\n",
       " 'pt_body': ([['взять_V',\n",
       "    'компания_S',\n",
       "    'сопоставимый_A',\n",
       "    'выручка_S',\n",
       "    'оценивать_V',\n",
       "    'влияние_S',\n",
       "    'курс_S',\n",
       "    'рубль_S',\n",
       "    'финансы_S'],\n",
       "   ['участник_S',\n",
       "    'производитель_S',\n",
       "    'удобрение_S',\n",
       "    'фосагро_S',\n",
       "    'большой_A',\n",
       "    'часть_S',\n",
       "    'выручка_S',\n",
       "    'получать_V',\n",
       "    'экспорт_S'],\n",
       "   ['участник_S',\n",
       "    'ориентировать_V',\n",
       "    'внутренний_A',\n",
       "    'рынок_S',\n",
       "    'компания_S',\n",
       "    'видео_S',\n",
       "    'продавать_V',\n",
       "    'электроника_S',\n",
       "    'техника_S'],\n",
       "   ['качество_S',\n",
       "    'отчет_S',\n",
       "    'взять_V',\n",
       "    'курс_S',\n",
       "    'рубль_S',\n",
       "    'доллар_S',\n",
       "    'оставаться_V',\n",
       "    'стабильный_A',\n",
       "    'находиться_V',\n",
       "    'диапазон_S']],)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
